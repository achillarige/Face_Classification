arguments: demo.py
--------------------
git hash: b'e5e86910a6705d42df3a4a8f281d8829e0c0cc3e'
--------------------
b'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\nindex d2a3eea..58149e3 100644\n--- a/src/align/align_dataset_mtcnn.py\n+++ b/src/align/align_dataset_mtcnn.py\n@@ -25,8 +25,10 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-from scipy import misc\n import sys\n+sys.path.append("..")\n+\n+from scipy import misc\n import os\n import argparse\n import tensorflow as tf\n@@ -99,26 +101,35 @@ def main(args):\n                             det = bounding_boxes[:,0:4]\n                             img_size = np.asarray(img.shape)[0:2]\n                             if nrof_faces>1:\n-                                bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\n-                                img_center = img_size / 2\n-                                offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\n-                                offset_dist_squared = np.sum(np.power(offsets,2.0),0)\n-                                index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\n-                                det = det[index,:]\n-                            det = np.squeeze(det)\n-                            bb = np.zeros(4, dtype=np.int32)\n-                            bb[0] = np.maximum(det[0]-args.margin/2, 0)\n-                            bb[1] = np.maximum(det[1]-args.margin/2, 0)\n-                            bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\n-                            bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\n-                            cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n-                            scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\'bilinear\')\n-                            nrof_successfully_aligned += 1\n-                            misc.imsave(output_filename, scaled)\n-                            text_file.write(\'%s %d %d %d %d\\n\' % (output_filename, bb[0], bb[1], bb[2], bb[3]))\n+                                count = 0\n+                                for sdet in det:\n+                                    bb = np.zeros(4, dtype=np.int32)\n+                                    bb[0] = np.maximum(sdet[0]-args.margin/2, 0)\n+                                    bb[1] = np.maximum(sdet[1]-args.margin/2, 0)\n+                                    bb[2] = np.minimum(sdet[2]+args.margin/2, img_size[1])\n+                                    bb[3] = np.minimum(sdet[3]+args.margin/2, img_size[0])\n+                                    cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n+                                    scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\'bilinear\')\n+                                    nrof_successfully_aligned += 1\n+                                    misc.imsave(output_filename[:-4]+"_grp"+str(count)+output_filename[-4:], scaled)\n+                                    text_file.write(\'%s %d %d %d %d\\n\' % (output_filename[:-4]+"_grp"+str(count)+output_filename[-4:], bb[0], bb[1], bb[2], bb[3]))\n+                                    count+=1\n+                            else:\n+                                det = np.squeeze(det)\n+                                bb = np.zeros(4, dtype=np.int32)\n+                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\n+                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\n+                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\n+                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\n+                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n+                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\'bilinear\')\n+                                nrof_successfully_aligned += 1\n+                                misc.imsave(output_filename, scaled)\n+                                text_file.write(\'%s %d %d %d %d\\n\' % (output_filename, bb[0], bb[1], bb[2], bb[3]))\n                         else:\n                             print(\'Unable to align "%s"\' % image_path)\n                             text_file.write(\'%s\\n\' % (output_filename))\n+                        \n                             \n     print(\'Total number of images: %d\' % nrof_images_total)\n     print(\'Number of successfully aligned images: %d\' % nrof_successfully_aligned)\n@@ -137,6 +148,7 @@ def parse_arguments(argv):\n         help=\'Shuffles the order of images to enable alignment using multiple processes.\', action=\'store_true\')\n     parser.add_argument(\'--gpu_memory_fraction\', type=float,\n         help=\'Upper bound on the amount of GPU memory that will be used by the process.\', default=1.0)\n+    print(parser.parse_args(argv))\n     return parser.parse_args(argv)\n \n if __name__ == \'__main__\':\ndiff --git a/src/align/align_dataset_userprofs.py b/src/align/align_dataset_userprofs.py\ndeleted file mode 100644\nindex d2a3eea..0000000\n--- a/src/align/align_dataset_userprofs.py\n+++ /dev/null\n@@ -1,143 +0,0 @@\n-"""Performs face alignment and stores face thumbnails in the output directory."""\n-# MIT License\n-# \n-# Copyright (c) 2016 David Sandberg\n-# \n-# Permission is hereby granted, free of charge, to any person obtaining a copy\n-# of this software and associated documentation files (the "Software"), to deal\n-# in the Software without restriction, including without limitation the rights\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n-# copies of the Software, and to permit persons to whom the Software is\n-# furnished to do so, subject to the following conditions:\n-# \n-# The above copyright notice and this permission notice shall be included in all\n-# copies or substantial portions of the Software.\n-# \n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n-# SOFTWARE.\n-\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from scipy import misc\n-import sys\n-import os\n-import argparse\n-import tensorflow as tf\n-import numpy as np\n-import facenet\n-import align.detect_face\n-import random\n-from time import sleep\n-\n-def main(args):\n-    sleep(random.random())\n-    output_dir = os.path.expanduser(args.output_dir)\n-    if not os.path.exists(output_dir):\n-        os.makedirs(output_dir)\n-    # Store some git revision info in a text file in the log directory\n-    src_path,_ = os.path.split(os.path.realpath(__file__))\n-    facenet.store_revision_info(src_path, output_dir, \' \'.join(sys.argv))\n-    dataset = facenet.get_dataset(args.input_dir)\n-    \n-    print(\'Creating networks and loading parameters\')\n-    \n-    with tf.Graph().as_default():\n-        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\n-        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n-        with sess.as_default():\n-            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\n-    \n-    minsize = 20 # minimum size of face\n-    threshold = [ 0.6, 0.7, 0.7 ]  # three steps\'s threshold\n-    factor = 0.709 # scale factor\n-\n-    # Add a random key to the filename to allow alignment using multiple processes\n-    random_key = np.random.randint(0, high=99999)\n-    bounding_boxes_filename = os.path.join(output_dir, \'bounding_boxes_%05d.txt\' % random_key)\n-    \n-    with open(bounding_boxes_filename, "w") as text_file:\n-        nrof_images_total = 0\n-        nrof_successfully_aligned = 0\n-        if args.random_order:\n-            random.shuffle(dataset)\n-        for cls in dataset:\n-            output_class_dir = os.path.join(output_dir, cls.name)\n-            if not os.path.exists(output_class_dir):\n-                os.makedirs(output_class_dir)\n-                if args.random_order:\n-                    random.shuffle(cls.image_paths)\n-            for image_path in cls.image_paths:\n-                nrof_images_total += 1\n-                filename = os.path.splitext(os.path.split(image_path)[1])[0]\n-                output_filename = os.path.join(output_class_dir, filename+\'.png\')\n-                print(image_path)\n-                if not os.path.exists(output_filename):\n-                    try:\n-                        img = misc.imread(image_path)\n-                    except (IOError, ValueError, IndexError) as e:\n-                        errorMessage = \'{}: {}\'.format(image_path, e)\n-                        print(errorMessage)\n-                    else:\n-                        if img.ndim<2:\n-                            print(\'Unable to align "%s"\' % image_path)\n-                            text_file.write(\'%s\\n\' % (output_filename))\n-                            continue\n-                        if img.ndim == 2:\n-                            img = facenet.to_rgb(img)\n-                        img = img[:,:,0:3]\n-    \n-                        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n-                        nrof_faces = bounding_boxes.shape[0]\n-                        if nrof_faces>0:\n-                            det = bounding_boxes[:,0:4]\n-                            img_size = np.asarray(img.shape)[0:2]\n-                            if nrof_faces>1:\n-                                bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\n-                                img_center = img_size / 2\n-                                offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\n-                                offset_dist_squared = np.sum(np.power(offsets,2.0),0)\n-                                index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\n-                                det = det[index,:]\n-                            det = np.squeeze(det)\n-                            bb = np.zeros(4, dtype=np.int32)\n-                            bb[0] = np.maximum(det[0]-args.margin/2, 0)\n-                            bb[1] = np.maximum(det[1]-args.margin/2, 0)\n-                            bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\n-                            bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\n-                            cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n-                            scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\'bilinear\')\n-                            nrof_successfully_aligned += 1\n-                            misc.imsave(output_filename, scaled)\n-                            text_file.write(\'%s %d %d %d %d\\n\' % (output_filename, bb[0], bb[1], bb[2], bb[3]))\n-                        else:\n-                            print(\'Unable to align "%s"\' % image_path)\n-                            text_file.write(\'%s\\n\' % (output_filename))\n-                            \n-    print(\'Total number of images: %d\' % nrof_images_total)\n-    print(\'Number of successfully aligned images: %d\' % nrof_successfully_aligned)\n-            \n-\n-def parse_arguments(argv):\n-    parser = argparse.ArgumentParser()\n-    \n-    parser.add_argument(\'input_dir\', type=str, help=\'Directory with unaligned images.\')\n-    parser.add_argument(\'output_dir\', type=str, help=\'Directory with aligned face thumbnails.\')\n-    parser.add_argument(\'--image_size\', type=int,\n-        help=\'Image size (height, width) in pixels.\', default=182)\n-    parser.add_argument(\'--margin\', type=int,\n-        help=\'Margin for the crop around the bounding box (height, width) in pixels.\', default=44)\n-    parser.add_argument(\'--random_order\', \n-        help=\'Shuffles the order of images to enable alignment using multiple processes.\', action=\'store_true\')\n-    parser.add_argument(\'--gpu_memory_fraction\', type=float,\n-        help=\'Upper bound on the amount of GPU memory that will be used by the process.\', default=1.0)\n-    return parser.parse_args(argv)\n-\n-if __name__ == \'__main__\':\n-    main(parse_arguments(sys.argv[1:]))\ndiff --git a/src/classifier.py b/src/classifier.py\nindex 749db4d..be8f9b7 100644\n--- a/src/classifier.py\n+++ b/src/classifier.py\n@@ -26,15 +26,18 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n+import sys\n+sys.path.append("..")\n+\n import tensorflow as tf\n import numpy as np\n import argparse\n import facenet\n import os\n-import sys\n+import shutil\n import math\n import pickle\n-from sklearn.svm import SVC\n+from sklearn import neighbors\n \n def main(args):\n   \n@@ -53,6 +56,10 @@ def main(args):\n                     dataset = test_set\n             else:\n                 dataset = facenet.get_dataset(args.data_dir)\n+            \n+            if (args.mode == \'CLASSIFY\'):\n+                training_set = facenet.get_dataset(args.train_dir)\n+                unaligned_set = facenet.get_dataset(args.unaligned_dir)\n \n             # Check that there are at least one training image per class\n             for cls in dataset:\n@@ -92,7 +99,7 @@ def main(args):\n             if (args.mode==\'TRAIN\'):\n                 # Train classifier\n                 print(\'Training classifier\')\n-                model = SVC(kernel=\'linear\', probability=True)\n+                model = neighbors.KNeighborsClassifier(n_neighbors=1)\n                 model.fit(emb_array, labels)\n             \n                 # Create a list of class names\n@@ -108,19 +115,46 @@ def main(args):\n                 print(\'Testing classifier\')\n                 with open(classifier_filename_exp, \'rb\') as infile:\n                     (model, class_names) = pickle.load(infile)\n-\n+                \n                 print(\'Loaded classifier model from file "%s"\' % classifier_filename_exp)\n \n                 predictions = model.predict_proba(emb_array)\n                 best_class_indices = np.argmax(predictions, axis=1)\n                 best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n-                \n+                                                \n                 for i in range(len(best_class_indices)):\n                     print(\'%4d  %s: %.3f\' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))\n-                    \n+\n+                #File movement to appropriate class in dataset\n+                for cls in dataset:\n+                    pths = cls.image_paths\n+                    count = 0\n+                    for pth in pths:\n+                        pname = pth[pth.rfind("/")+1:]\n+                        print(pname)\n+                        #handling group photos\n+                        if "_grp" in pname:\n+                            print("hahahahahahahahahhahahahahahahah")\n+                            pname = pname[:pname.rfind("_grp")] + pname[pname.rfind("."):]\n+                            og_path = pth[:pth.rfind("/")+1]+pname\n+                            og_path = og_path.replace("aligned","unaligned")\n+                            new_class_name = str(class_names[best_class_indices[count]]).replace(" ","_")\n+                            destination = "datasets/face_data_unaligned/" + new_class_name +"/"+pname\n+                            shutil.copy2(og_path, destination)\n+                        else:\n+                            new_class_name = str(class_names[best_class_indices[count]]).replace(" ","_")\n+                            destination = "datasets/face_data_unaligned/" + new_class_name +"/"+pname\n+                            og_path = pth.replace("aligned", "unaligned")\n+                            os.rename(og_path, destination)  \n+                        count+=1    \n+                \n+                #removing aligned unsorted dataset so that they won\'t be reclassified\n+                #shutil.rmtree(args.data_dir)\n+                                 \n                 accuracy = np.mean(np.equal(best_class_indices, labels))\n                 print(\'Accuracy: %.3f\' % accuracy)\n-                \n+\n+\n             \n def split_dataset(dataset, min_nrof_images_per_class, nrof_train_images_per_class):\n     train_set = []\n@@ -148,6 +182,10 @@ def parse_arguments(argv):\n     parser.add_argument(\'classifier_filename\', \n         help=\'Classifier model file name as a pickle (.pkl) file. \' + \n         \'For training this is the output and for classification this is an input.\')\n+    parser.add_argument(\'--train_dir\', type=str,\n+        help=\'Path to the data directory containing aligned LFW face patches.\')\n+    parser.add_argument(\'--unaligned_dir\', type=str,\n+        help=\'Path to the data directory containing aligned LFW face patches.\', default=\'datasets/unsorted_unaligned\')\n     parser.add_argument(\'--use_split_dataset\', \n         help=\'Indicates that the dataset specified by data_dir should be split into a training and test set. \' +  \n         \'Otherwise a separate test set can be specified using the test_data_dir option.\', action=\'store_true\')\ndiff --git a/src/facenet.py b/src/facenet.py\nindex 4f139ee..952555b 100644\n--- a/src/facenet.py\n+++ b/src/facenet.py\n@@ -340,7 +340,7 @@ def get_dataset(paths, has_class_directories=True):\n def get_image_paths(facedir):\n     image_paths = []\n     if os.path.isdir(facedir):\n-        images = os.listdir(facedir)\n+        images = [a for a in os.listdir(facedir) if not a.startswith(\'.\')]\n         image_paths = [os.path.join(facedir,img) for img in images]\n     return image_paths'