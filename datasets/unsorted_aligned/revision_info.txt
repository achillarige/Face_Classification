arguments: demo.py
--------------------
git hash: b'4faf590600f122c3cd2ab3ab3c85bd3bd2d00822'
--------------------
b'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\nindex d2a3eea..044c156 100644\n--- a/src/align/align_dataset_mtcnn.py\n+++ b/src/align/align_dataset_mtcnn.py\n@@ -25,8 +25,10 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-from scipy import misc\n import sys\n+sys.path.append("..")\n+\n+from scipy import misc\n import os\n import argparse\n import tensorflow as tf\n@@ -99,26 +101,35 @@ def main(args):\n                             det = bounding_boxes[:,0:4]\n                             img_size = np.asarray(img.shape)[0:2]\n                             if nrof_faces>1:\n-                                bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\n-                                img_center = img_size / 2\n-                                offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\n-                                offset_dist_squared = np.sum(np.power(offsets,2.0),0)\n-                                index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\n-                                det = det[index,:]\n-                            det = np.squeeze(det)\n-                            bb = np.zeros(4, dtype=np.int32)\n-                            bb[0] = np.maximum(det[0]-args.margin/2, 0)\n-                            bb[1] = np.maximum(det[1]-args.margin/2, 0)\n-                            bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\n-                            bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\n-                            cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n-                            scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\'bilinear\')\n-                            nrof_successfully_aligned += 1\n-                            misc.imsave(output_filename, scaled)\n-                            text_file.write(\'%s %d %d %d %d\\n\' % (output_filename, bb[0], bb[1], bb[2], bb[3]))\n+                                count = 0\n+                                for sdet in det:\n+                                    bb = np.zeros(4, dtype=np.int32)\n+                                    bb[0] = np.maximum(sdet[0]-args.margin/2, 0)\n+                                    bb[1] = np.maximum(sdet[1]-args.margin/2, 0)\n+                                    bb[2] = np.minimum(sdet[2]+args.margin/2, img_size[1])\n+                                    bb[3] = np.minimum(sdet[3]+args.margin/2, img_size[0])\n+                                    cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n+                                    scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\'bilinear\')\n+                                    nrof_successfully_aligned += 1\n+                                    misc.imsave(output_filename[:-4]+"_"+str(count)+output_filename[-4:], scaled)\n+                                    text_file.write(\'%s %d %d %d %d\\n\' % (output_filename[:-4]+"_"+str(count)+output_filename[-4:], bb[0], bb[1], bb[2], bb[3]))\n+                                    count+=1\n+                            else:\n+                                det = np.squeeze(det)\n+                                bb = np.zeros(4, dtype=np.int32)\n+                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\n+                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\n+                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\n+                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\n+                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n+                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\'bilinear\')\n+                                nrof_successfully_aligned += 1\n+                                misc.imsave(output_filename, scaled)\n+                                text_file.write(\'%s %d %d %d %d\\n\' % (output_filename, bb[0], bb[1], bb[2], bb[3]))\n                         else:\n                             print(\'Unable to align "%s"\' % image_path)\n                             text_file.write(\'%s\\n\' % (output_filename))\n+                        \n                             \n     print(\'Total number of images: %d\' % nrof_images_total)\n     print(\'Number of successfully aligned images: %d\' % nrof_successfully_aligned)\n@@ -137,6 +148,7 @@ def parse_arguments(argv):\n         help=\'Shuffles the order of images to enable alignment using multiple processes.\', action=\'store_true\')\n     parser.add_argument(\'--gpu_memory_fraction\', type=float,\n         help=\'Upper bound on the amount of GPU memory that will be used by the process.\', default=1.0)\n+    print(parser.parse_args(argv))\n     return parser.parse_args(argv)\n \n if __name__ == \'__main__\':\ndiff --git a/src/classifier.py b/src/classifier.py\nindex 749db4d..dabeab9 100644\n--- a/src/classifier.py\n+++ b/src/classifier.py\n@@ -26,15 +26,17 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n+import sys\n+sys.path.append("..")\n+\n import tensorflow as tf\n import numpy as np\n import argparse\n import facenet\n import os\n-import sys\n import math\n import pickle\n-from sklearn.svm import SVC\n+from sklearn import neighbors\n \n def main(args):\n   \n@@ -53,6 +55,10 @@ def main(args):\n                     dataset = test_set\n             else:\n                 dataset = facenet.get_dataset(args.data_dir)\n+            \n+            if (args.mode == \'CLASSIFY\'):\n+                training_set = facenet.get_dataset(args.train_dir)\n+                unaligned_set = facenet.get_dataset(args.unaligned_dir)\n \n             # Check that there are at least one training image per class\n             for cls in dataset:\n@@ -92,7 +98,7 @@ def main(args):\n             if (args.mode==\'TRAIN\'):\n                 # Train classifier\n                 print(\'Training classifier\')\n-                model = SVC(kernel=\'linear\', probability=True)\n+                model = neighbors.KNeighborsClassifier(n_neighbors=1)\n                 model.fit(emb_array, labels)\n             \n                 # Create a list of class names\n@@ -108,16 +114,32 @@ def main(args):\n                 print(\'Testing classifier\')\n                 with open(classifier_filename_exp, \'rb\') as infile:\n                     (model, class_names) = pickle.load(infile)\n+                \n+                print(class_names)\n \n                 print(\'Loaded classifier model from file "%s"\' % classifier_filename_exp)\n \n                 predictions = model.predict_proba(emb_array)\n                 best_class_indices = np.argmax(predictions, axis=1)\n                 best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n-                \n+                                                \n                 for i in range(len(best_class_indices)):\n                     print(\'%4d  %s: %.3f\' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))\n-                    \n+\n+                #File movement to appropriate class in dataset\n+                for cls in unaligned_set:\n+                    pths = cls.image_paths\n+                    count = 0\n+                    for pth in pths:\n+                        new_class_name = str(class_names[best_class_indices[count]]).replace(" ","_")\n+                        destination = "datasets/face_data_unaligned/" + new_class_name +"/"+pth[pth.rfind("/")+1:]\n+                        os.rename(pth,destination)  \n+                        count+=1    \n+                \'\'\'for cls in dataset:\n+                    pths = cls.image_paths\n+                    for pth in paths:\n+                        os.remove(pth)\'\'\'\n+                                 \n                 accuracy = np.mean(np.equal(best_class_indices, labels))\n                 print(\'Accuracy: %.3f\' % accuracy)\n                 \n@@ -148,6 +170,10 @@ def parse_arguments(argv):\n     parser.add_argument(\'classifier_filename\', \n         help=\'Classifier model file name as a pickle (.pkl) file. \' + \n         \'For training this is the output and for classification this is an input.\')\n+    parser.add_argument(\'--train_dir\', type=str,\n+        help=\'Path to the data directory containing aligned LFW face patches.\')\n+    parser.add_argument(\'--unaligned_dir\', type=str,\n+        help=\'Path to the data directory containing aligned LFW face patches.\', default=\'datasets/unsorted_unaligned\')\n     parser.add_argument(\'--use_split_dataset\', \n         help=\'Indicates that the dataset specified by data_dir should be split into a training and test set. \' +  \n         \'Otherwise a separate test set can be specified using the test_data_dir option.\', action=\'store_true\')\ndiff --git a/src/facenet.py b/src/facenet.py\nindex 4f139ee..952555b 100644\n--- a/src/facenet.py\n+++ b/src/facenet.py\n@@ -340,7 +340,7 @@ def get_dataset(paths, has_class_directories=True):\n def get_image_paths(facedir):\n     image_paths = []\n     if os.path.isdir(facedir):\n-        images = os.listdir(facedir)\n+        images = [a for a in os.listdir(facedir) if not a.startswith(\'.\')]\n         image_paths = [os.path.join(facedir,img) for img in images]\n     return image_paths'