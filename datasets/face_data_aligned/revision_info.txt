arguments: demo.py
--------------------
git hash: b'6d8478d2dc0d287bccdd2863a8444b56641599b4'
--------------------
b'diff --git a/.DS_Store b/.DS_Store\nindex 2085760..17e5a37 100644\nBinary files a/.DS_Store and b/.DS_Store differ\ndiff --git a/.bash_profile b/.bash_profile\ndeleted file mode 100644\nindex 5509b20..0000000\n--- a/.bash_profile\n+++ /dev/null\n@@ -1 +0,0 @@\n-export PYTHONPATH=/Users/ananth/Desktop/Machine\\ Learning/Face_Classification/facenet/src\ndiff --git a/__pycache__/face_alignment.cpython-36.pyc b/__pycache__/face_alignment.cpython-36.pyc\nindex 7dc2c56..6d86f44 100644\nBinary files a/__pycache__/face_alignment.cpython-36.pyc and b/__pycache__/face_alignment.cpython-36.pyc differ\ndiff --git a/align_dataset_userprofs.py b/align_dataset_userprofs.py\nindex d2a3eea..be5e4c2 100644\n--- a/align_dataset_userprofs.py\n+++ b/align_dataset_userprofs.py\n@@ -98,6 +98,8 @@ def main(args):\n                         if nrof_faces>0:\n                             det = bounding_boxes[:,0:4]\n                             img_size = np.asarray(img.shape)[0:2]\n+                            #potentially find the face that matches everything else in the class, and use that face for alignment\n+                            #assuming that there are multiple pictures in that dataset\n                             if nrof_faces>1:\n                                 bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\n                                 img_center = img_size / 2\ndiff --git a/datasets/.DS_Store b/datasets/.DS_Store\nindex 0c90fbd..6690651 100644\nBinary files a/datasets/.DS_Store and b/datasets/.DS_Store differ\ndiff --git a/datasets/face_data_aligned/bounding_boxes_20314.txt b/datasets/face_data_aligned/bounding_boxes_20314.txt\ndeleted file mode 100644\nindex fcb1749..0000000\n--- a/datasets/face_data_aligned/bounding_boxes_20314.txt\n+++ /dev/null\n@@ -1,7 +0,0 @@\n-datasets/face_data_aligned/Nick_Crompton/Nick_1.png 64 43 237 249\n-datasets/face_data_aligned/Nihal_George/Nihal_1.png 33 20 130 129\n-datasets/face_data_aligned/Evan_Breisch/Evan.png 931 378 1340 885\n-datasets/face_data_aligned/Jake_Paul/Jake_1.png 272 129 591 554\n-datasets/face_data_aligned/Vishal_Joshi/Vishal.png 339 363 706 842\n-datasets/face_data_aligned/Clare_Monahan/Clare.png 1239 634 1431 870\n-datasets/face_data_aligned/Ananth_Chillarige/Ananth_1.png 56 23 150 133\ndiff --git a/datasets/face_data_aligned/revision_info.txt b/datasets/face_data_aligned/revision_info.txt\nindex 26c1dc5..6aacaff 100644\n--- a/datasets/face_data_aligned/revision_info.txt\n+++ b/datasets/face_data_aligned/revision_info.txt\n@@ -1,5 +1,5 @@\n arguments: demo.py\n --------------------\n-git hash: b\'4faf590600f122c3cd2ab3ab3c85bd3bd2d00822\'\n+git hash: b\'6d8478d2dc0d287bccdd2863a8444b56641599b4\'\n --------------------\n-b\'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\\nindex d2a3eea..044c156 100644\\n--- a/src/align/align_dataset_mtcnn.py\\n+++ b/src/align/align_dataset_mtcnn.py\\n@@ -25,8 +25,10 @@ from __future__ import absolute_import\\n from __future__ import division\\n from __future__ import print_function\\n \\n-from scipy import misc\\n import sys\\n+sys.path.append("..")\\n+\\n+from scipy import misc\\n import os\\n import argparse\\n import tensorflow as tf\\n@@ -99,26 +101,35 @@ def main(args):\\n                             det = bounding_boxes[:,0:4]\\n                             img_size = np.asarray(img.shape)[0:2]\\n                             if nrof_faces>1:\\n-                                bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\\n-                                img_center = img_size / 2\\n-                                offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\\n-                                offset_dist_squared = np.sum(np.power(offsets,2.0),0)\\n-                                index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\\n-                                det = det[index,:]\\n-                            det = np.squeeze(det)\\n-                            bb = np.zeros(4, dtype=np.int32)\\n-                            bb[0] = np.maximum(det[0]-args.margin/2, 0)\\n-                            bb[1] = np.maximum(det[1]-args.margin/2, 0)\\n-                            bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\n-                            bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\n-                            cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\n-                            scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\'bilinear\\\')\\n-                            nrof_successfully_aligned += 1\\n-                            misc.imsave(output_filename, scaled)\\n-                            text_file.write(\\\'%s %d %d %d %d\\\\n\\\' % (output_filename, bb[0], bb[1], bb[2], bb[3]))\\n+                                count = 0\\n+                                for sdet in det:\\n+                                    bb = np.zeros(4, dtype=np.int32)\\n+                                    bb[0] = np.maximum(sdet[0]-args.margin/2, 0)\\n+                                    bb[1] = np.maximum(sdet[1]-args.margin/2, 0)\\n+                                    bb[2] = np.minimum(sdet[2]+args.margin/2, img_size[1])\\n+                                    bb[3] = np.minimum(sdet[3]+args.margin/2, img_size[0])\\n+                                    cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\n+                                    scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\'bilinear\\\')\\n+                                    nrof_successfully_aligned += 1\\n+                                    misc.imsave(output_filename[:-4]+"_"+str(count)+output_filename[-4:], scaled)\\n+                                    text_file.write(\\\'%s %d %d %d %d\\\\n\\\' % (output_filename[:-4]+"_"+str(count)+output_filename[-4:], bb[0], bb[1], bb[2], bb[3]))\\n+                                    count+=1\\n+                            else:\\n+                                det = np.squeeze(det)\\n+                                bb = np.zeros(4, dtype=np.int32)\\n+                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\\n+                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\\n+                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\n+                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\n+                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\n+                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\'bilinear\\\')\\n+                                nrof_successfully_aligned += 1\\n+                                misc.imsave(output_filename, scaled)\\n+                                text_file.write(\\\'%s %d %d %d %d\\\\n\\\' % (output_filename, bb[0], bb[1], bb[2], bb[3]))\\n                         else:\\n                             print(\\\'Unable to align "%s"\\\' % image_path)\\n                             text_file.write(\\\'%s\\\\n\\\' % (output_filename))\\n+                        \\n                             \\n     print(\\\'Total number of images: %d\\\' % nrof_images_total)\\n     print(\\\'Number of successfully aligned images: %d\\\' % nrof_successfully_aligned)\\n@@ -137,6 +148,7 @@ def parse_arguments(argv):\\n         help=\\\'Shuffles the order of images to enable alignment using multiple processes.\\\', action=\\\'store_true\\\')\\n     parser.add_argument(\\\'--gpu_memory_fraction\\\', type=float,\\n         help=\\\'Upper bound on the amount of GPU memory that will be used by the process.\\\', default=1.0)\\n+    print(parser.parse_args(argv))\\n     return parser.parse_args(argv)\\n \\n if __name__ == \\\'__main__\\\':\\ndiff --git a/src/classifier.py b/src/classifier.py\\nindex 749db4d..d76cfff 100644\\n--- a/src/classifier.py\\n+++ b/src/classifier.py\\n@@ -26,15 +26,18 @@ from __future__ import absolute_import\\n from __future__ import division\\n from __future__ import print_function\\n \\n+import sys\\n+sys.path.append("..")\\n+\\n import tensorflow as tf\\n import numpy as np\\n import argparse\\n import facenet\\n import os\\n-import sys\\n+import shutil\\n import math\\n import pickle\\n-from sklearn.svm import SVC\\n+from sklearn import neighbors\\n \\n def main(args):\\n   \\n@@ -53,6 +56,10 @@ def main(args):\\n                     dataset = test_set\\n             else:\\n                 dataset = facenet.get_dataset(args.data_dir)\\n+            \\n+            if (args.mode == \\\'CLASSIFY\\\'):\\n+                training_set = facenet.get_dataset(args.train_dir)\\n+                unaligned_set = facenet.get_dataset(args.unaligned_dir)\\n \\n             # Check that there are at least one training image per class\\n             for cls in dataset:\\n@@ -92,7 +99,7 @@ def main(args):\\n             if (args.mode==\\\'TRAIN\\\'):\\n                 # Train classifier\\n                 print(\\\'Training classifier\\\')\\n-                model = SVC(kernel=\\\'linear\\\', probability=True)\\n+                model = neighbors.KNeighborsClassifier(n_neighbors=1)\\n                 model.fit(emb_array, labels)\\n             \\n                 # Create a list of class names\\n@@ -108,19 +115,35 @@ def main(args):\\n                 print(\\\'Testing classifier\\\')\\n                 with open(classifier_filename_exp, \\\'rb\\\') as infile:\\n                     (model, class_names) = pickle.load(infile)\\n+                \\n+                print(class_names)\\n \\n                 print(\\\'Loaded classifier model from file "%s"\\\' % classifier_filename_exp)\\n \\n                 predictions = model.predict_proba(emb_array)\\n                 best_class_indices = np.argmax(predictions, axis=1)\\n                 best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\\n-                \\n+                                                \\n                 for i in range(len(best_class_indices)):\\n                     print(\\\'%4d  %s: %.3f\\\' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))\\n-                    \\n+\\n+                #File movement to appropriate class in dataset\\n+                for cls in unaligned_set:\\n+                    pths = cls.image_paths\\n+                    count = 0\\n+                    for pth in pths:\\n+                        new_class_name = str(class_names[best_class_indices[count]]).replace(" ","_")\\n+                        destination = "datasets/face_data_unaligned/" + new_class_name +"/"+pth[pth.rfind("/")+1:]\\n+                        os.rename(pth,destination)  \\n+                        count+=1    \\n+                \\n+                #removing aligned unsorted dataset so that they won\\\'t be reclassified\\n+                shutil.rmtree(args.data_dir)\\n+                                 \\n                 accuracy = np.mean(np.equal(best_class_indices, labels))\\n                 print(\\\'Accuracy: %.3f\\\' % accuracy)\\n-                \\n+\\n+\\n             \\n def split_dataset(dataset, min_nrof_images_per_class, nrof_train_images_per_class):\\n     train_set = []\\n@@ -148,6 +171,10 @@ def parse_arguments(argv):\\n     parser.add_argument(\\\'classifier_filename\\\', \\n         help=\\\'Classifier model file name as a pickle (.pkl) file. \\\' + \\n         \\\'For training this is the output and for classification this is an input.\\\')\\n+    parser.add_argument(\\\'--train_dir\\\', type=str,\\n+        help=\\\'Path to the data directory containing aligned LFW face patches.\\\')\\n+    parser.add_argument(\\\'--unaligned_dir\\\', type=str,\\n+        help=\\\'Path to the data directory containing aligned LFW face patches.\\\', default=\\\'datasets/unsorted_unaligned\\\')\\n     parser.add_argument(\\\'--use_split_dataset\\\', \\n         help=\\\'Indicates that the dataset specified by data_dir should be split into a training and test set. \\\' +  \\n         \\\'Otherwise a separate test set can be specified using the test_data_dir option.\\\', action=\\\'store_true\\\')\\ndiff --git a/src/facenet.py b/src/facenet.py\\nindex 4f139ee..952555b 100644\\n--- a/src/facenet.py\\n+++ b/src/facenet.py\\n@@ -340,7 +340,7 @@ def get_dataset(paths, has_class_directories=True):\\n def get_image_paths(facedir):\\n     image_paths = []\\n     if os.path.isdir(facedir):\\n-        images = os.listdir(facedir)\\n+        images = [a for a in os.listdir(facedir) if not a.startswith(\\\'.\\\')]\\n         image_paths = [os.path.join(facedir,img) for img in images]\\n     return image_paths\'\n\\ No newline at end of file\n+b\'diff --git a/.DS_Store b/.DS_Store\\nindex 2085760..17e5a37 100644\\nBinary files a/.DS_Store and b/.DS_Store differ\\ndiff --git a/.bash_profile b/.bash_profile\\ndeleted file mode 100644\\nindex 5509b20..0000000\\n--- a/.bash_profile\\n+++ /dev/null\\n@@ -1 +0,0 @@\\n-export PYTHONPATH=/Users/ananth/Desktop/Machine\\\\ Learning/Face_Classification/facenet/src\\ndiff --git a/__pycache__/face_alignment.cpython-36.pyc b/__pycache__/face_alignment.cpython-36.pyc\\nindex 7dc2c56..6d86f44 100644\\nBinary files a/__pycache__/face_alignment.cpython-36.pyc and b/__pycache__/face_alignment.cpython-36.pyc differ\\ndiff --git a/align_dataset_userprofs.py b/align_dataset_userprofs.py\\nindex d2a3eea..be5e4c2 100644\\n--- a/align_dataset_userprofs.py\\n+++ b/align_dataset_userprofs.py\\n@@ -98,6 +98,8 @@ def main(args):\\n                         if nrof_faces>0:\\n                             det = bounding_boxes[:,0:4]\\n                             img_size = np.asarray(img.shape)[0:2]\\n+                            #potentially find the face that matches everything else in the class, and use that face for alignment\\n+                            #assuming that there are multiple pictures in that dataset\\n                             if nrof_faces>1:\\n                                 bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\\n                                 img_center = img_size / 2\\ndiff --git a/datasets/.DS_Store b/datasets/.DS_Store\\nindex 0c90fbd..c67c0f7 100644\\nBinary files a/datasets/.DS_Store and b/datasets/.DS_Store differ\\ndiff --git a/datasets/face_data_aligned/bounding_boxes_20314.txt b/datasets/face_data_aligned/bounding_boxes_20314.txt\\ndeleted file mode 100644\\nindex fcb1749..0000000\\n--- a/datasets/face_data_aligned/bounding_boxes_20314.txt\\n+++ /dev/null\\n@@ -1,7 +0,0 @@\\n-datasets/face_data_aligned/Nick_Crompton/Nick_1.png 64 43 237 249\\n-datasets/face_data_aligned/Nihal_George/Nihal_1.png 33 20 130 129\\n-datasets/face_data_aligned/Evan_Breisch/Evan.png 931 378 1340 885\\n-datasets/face_data_aligned/Jake_Paul/Jake_1.png 272 129 591 554\\n-datasets/face_data_aligned/Vishal_Joshi/Vishal.png 339 363 706 842\\n-datasets/face_data_aligned/Clare_Monahan/Clare.png 1239 634 1431 870\\n-datasets/face_data_aligned/Ananth_Chillarige/Ananth_1.png 56 23 150 133\\ndiff --git a/datasets/face_data_aligned/revision_info.txt b/datasets/face_data_aligned/revision_info.txt\\nindex 26c1dc5..670548e 100644\\n--- a/datasets/face_data_aligned/revision_info.txt\\n+++ b/datasets/face_data_aligned/revision_info.txt\\n@@ -1,5 +1,5 @@\\n arguments: demo.py\\n --------------------\\n-git hash: b\\\'4faf590600f122c3cd2ab3ab3c85bd3bd2d00822\\\'\\n+git hash: b\\\'6d8478d2dc0d287bccdd2863a8444b56641599b4\\\'\\n --------------------\\n-b\\\'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\\\\nindex d2a3eea..044c156 100644\\\\n--- a/src/align/align_dataset_mtcnn.py\\\\n+++ b/src/align/align_dataset_mtcnn.py\\\\n@@ -25,8 +25,10 @@ from __future__ import absolute_import\\\\n from __future__ import division\\\\n from __future__ import print_function\\\\n \\\\n-from scipy import misc\\\\n import sys\\\\n+sys.path.append("..")\\\\n+\\\\n+from scipy import misc\\\\n import os\\\\n import argparse\\\\n import tensorflow as tf\\\\n@@ -99,26 +101,35 @@ def main(args):\\\\n                             det = bounding_boxes[:,0:4]\\\\n                             img_size = np.asarray(img.shape)[0:2]\\\\n                             if nrof_faces>1:\\\\n-                                bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\\\\n-                                img_center = img_size / 2\\\\n-                                offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\\\\n-                                offset_dist_squared = np.sum(np.power(offsets,2.0),0)\\\\n-                                index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\\\\n-                                det = det[index,:]\\\\n-                            det = np.squeeze(det)\\\\n-                            bb = np.zeros(4, dtype=np.int32)\\\\n-                            bb[0] = np.maximum(det[0]-args.margin/2, 0)\\\\n-                            bb[1] = np.maximum(det[1]-args.margin/2, 0)\\\\n-                            bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\\\n-                            bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\\\n-                            cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\n-                            scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\\\\\'bilinear\\\\\\\')\\\\n-                            nrof_successfully_aligned += 1\\\\n-                            misc.imsave(output_filename, scaled)\\\\n-                            text_file.write(\\\\\\\'%s %d %d %d %d\\\\\\\\n\\\\\\\' % (output_filename, bb[0], bb[1], bb[2], bb[3]))\\\\n+                                count = 0\\\\n+                                for sdet in det:\\\\n+                                    bb = np.zeros(4, dtype=np.int32)\\\\n+                                    bb[0] = np.maximum(sdet[0]-args.margin/2, 0)\\\\n+                                    bb[1] = np.maximum(sdet[1]-args.margin/2, 0)\\\\n+                                    bb[2] = np.minimum(sdet[2]+args.margin/2, img_size[1])\\\\n+                                    bb[3] = np.minimum(sdet[3]+args.margin/2, img_size[0])\\\\n+                                    cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\n+                                    scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\\\\\'bilinear\\\\\\\')\\\\n+                                    nrof_successfully_aligned += 1\\\\n+                                    misc.imsave(output_filename[:-4]+"_"+str(count)+output_filename[-4:], scaled)\\\\n+                                    text_file.write(\\\\\\\'%s %d %d %d %d\\\\\\\\n\\\\\\\' % (output_filename[:-4]+"_"+str(count)+output_filename[-4:], bb[0], bb[1], bb[2], bb[3]))\\\\n+                                    count+=1\\\\n+                            else:\\\\n+                                det = np.squeeze(det)\\\\n+                                bb = np.zeros(4, dtype=np.int32)\\\\n+                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\\\\n+                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\\\\n+                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\\\n+                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\\\n+                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\n+                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\\\\\'bilinear\\\\\\\')\\\\n+                                nrof_successfully_aligned += 1\\\\n+                                misc.imsave(output_filename, scaled)\\\\n+                                text_file.write(\\\\\\\'%s %d %d %d %d\\\\\\\\n\\\\\\\' % (output_filename, bb[0], bb[1], bb[2], bb[3]))\\\\n                         else:\\\\n                             print(\\\\\\\'Unable to align "%s"\\\\\\\' % image_path)\\\\n                             text_file.write(\\\\\\\'%s\\\\\\\\n\\\\\\\' % (output_filename))\\\\n+                        \\\\n                             \\\\n     print(\\\\\\\'Total number of images: %d\\\\\\\' % nrof_images_total)\\\\n     print(\\\\\\\'Number of successfully aligned images: %d\\\\\\\' % nrof_successfully_aligned)\\\\n@@ -137,6 +148,7 @@ def parse_arguments(argv):\\\\n         help=\\\\\\\'Shuffles the order of images to enable alignment using multiple processes.\\\\\\\', action=\\\\\\\'store_true\\\\\\\')\\\\n     parser.add_argument(\\\\\\\'--gpu_memory_fraction\\\\\\\', type=float,\\\\n         help=\\\\\\\'Upper bound on the amount of GPU memory that will be used by the process.\\\\\\\', default=1.0)\\\\n+    print(parser.parse_args(argv))\\\\n     return parser.parse_args(argv)\\\\n \\\\n if __name__ == \\\\\\\'__main__\\\\\\\':\\\\ndiff --git a/src/classifier.py b/src/classifier.py\\\\nindex 749db4d..d76cfff 100644\\\\n--- a/src/classifier.py\\\\n+++ b/src/classifier.py\\\\n@@ -26,15 +26,18 @@ from __future__ import absolute_import\\\\n from __future__ import division\\\\n from __future__ import print_function\\\\n \\\\n+import sys\\\\n+sys.path.append("..")\\\\n+\\\\n import tensorflow as tf\\\\n import numpy as np\\\\n import argparse\\\\n import facenet\\\\n import os\\\\n-import sys\\\\n+import shutil\\\\n import math\\\\n import pickle\\\\n-from sklearn.svm import SVC\\\\n+from sklearn import neighbors\\\\n \\\\n def main(args):\\\\n   \\\\n@@ -53,6 +56,10 @@ def main(args):\\\\n                     dataset = test_set\\\\n             else:\\\\n                 dataset = facenet.get_dataset(args.data_dir)\\\\n+            \\\\n+            if (args.mode == \\\\\\\'CLASSIFY\\\\\\\'):\\\\n+                training_set = facenet.get_dataset(args.train_dir)\\\\n+                unaligned_set = facenet.get_dataset(args.unaligned_dir)\\\\n \\\\n             # Check that there are at least one training image per class\\\\n             for cls in dataset:\\\\n@@ -92,7 +99,7 @@ def main(args):\\\\n             if (args.mode==\\\\\\\'TRAIN\\\\\\\'):\\\\n                 # Train classifier\\\\n                 print(\\\\\\\'Training classifier\\\\\\\')\\\\n-                model = SVC(kernel=\\\\\\\'linear\\\\\\\', probability=True)\\\\n+                model = neighbors.KNeighborsClassifier(n_neighbors=1)\\\\n                 model.fit(emb_array, labels)\\\\n             \\\\n                 # Create a list of class names\\\\n@@ -108,19 +115,35 @@ def main(args):\\\\n                 print(\\\\\\\'Testing classifier\\\\\\\')\\\\n                 with open(classifier_filename_exp, \\\\\\\'rb\\\\\\\') as infile:\\\\n                     (model, class_names) = pickle.load(infile)\\\\n+                \\\\n+                print(class_names)\\\\n \\\\n                 print(\\\\\\\'Loaded classifier model from file "%s"\\\\\\\' % classifier_filename_exp)\\\\n \\\\n                 predictions = model.predict_proba(emb_array)\\\\n                 best_class_indices = np.argmax(predictions, axis=1)\\\\n                 best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\\\\n-                \\\\n+                                                \\\\n                 for i in range(len(best_class_indices)):\\\\n                     print(\\\\\\\'%4d  %s: %.3f\\\\\\\' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))\\\\n-                    \\\\n+\\\\n+                #File movement to appropriate class in dataset\\\\n+                for cls in unaligned_set:\\\\n+                    pths = cls.image_paths\\\\n+                    count = 0\\\\n+                    for pth in pths:\\\\n+                        new_class_name = str(class_names[best_class_indices[count]]).replace(" ","_")\\\\n+                        destination = "datasets/face_data_unaligned/" + new_class_name +"/"+pth[pth.rfind("/")+1:]\\\\n+                        os.rename(pth,destination)  \\\\n+                        count+=1    \\\\n+                \\\\n+                #removing aligned unsorted dataset so that they won\\\\\\\'t be reclassified\\\\n+                shutil.rmtree(args.data_dir)\\\\n+                                 \\\\n                 accuracy = np.mean(np.equal(best_class_indices, labels))\\\\n                 print(\\\\\\\'Accuracy: %.3f\\\\\\\' % accuracy)\\\\n-                \\\\n+\\\\n+\\\\n             \\\\n def split_dataset(dataset, min_nrof_images_per_class, nrof_train_images_per_class):\\\\n     train_set = []\\\\n@@ -148,6 +171,10 @@ def parse_arguments(argv):\\\\n     parser.add_argument(\\\\\\\'classifier_filename\\\\\\\', \\\\n         help=\\\\\\\'Classifier model file name as a pickle (.pkl) file. \\\\\\\' + \\\\n         \\\\\\\'For training this is the output and for classification this is an input.\\\\\\\')\\\\n+    parser.add_argument(\\\\\\\'--train_dir\\\\\\\', type=str,\\\\n+        help=\\\\\\\'Path to the data directory containing aligned LFW face patches.\\\\\\\')\\\\n+    parser.add_argument(\\\\\\\'--unaligned_dir\\\\\\\', type=str,\\\\n+        help=\\\\\\\'Path to the data directory containing aligned LFW face patches.\\\\\\\', default=\\\\\\\'datasets/unsorted_unaligned\\\\\\\')\\\\n     parser.add_argument(\\\\\\\'--use_split_dataset\\\\\\\', \\\\n         help=\\\\\\\'Indicates that the dataset specified by data_dir should be split into a training and test set. \\\\\\\' +  \\\\n         \\\\\\\'Otherwise a separate test set can be specified using the test_data_dir option.\\\\\\\', action=\\\\\\\'store_true\\\\\\\')\\\\ndiff --git a/src/facenet.py b/src/facenet.py\\\\nindex 4f139ee..952555b 100644\\\\n--- a/src/facenet.py\\\\n+++ b/src/facenet.py\\\\n@@ -340,7 +340,7 @@ def get_dataset(paths, has_class_directories=True):\\\\n def get_image_paths(facedir):\\\\n     image_paths = []\\\\n     if os.path.isdir(facedir):\\\\n-        images = os.listdir(facedir)\\\\n+        images = [a for a in os.listdir(facedir) if not a.startswith(\\\\\\\'.\\\\\\\')]\\\\n         image_paths = [os.path.join(facedir,img) for img in images]\\\\n     return image_paths\\\'\\n\\\\ No newline at end of file\\n+b\\\'diff --git a/.DS_Store b/.DS_Store\\\\nindex 2085760..17e5a37 100644\\\\nBinary files a/.DS_Store and b/.DS_Store differ\\\\ndiff --git a/.bash_profile b/.bash_profile\\\\ndeleted file mode 100644\\\\nindex 5509b20..0000000\\\\n--- a/.bash_profile\\\\n+++ /dev/null\\\\n@@ -1 +0,0 @@\\\\n-export PYTHONPATH=/Users/ananth/Desktop/Machine\\\\\\\\ Learning/Face_Classification/facenet/src\\\\ndiff --git a/__pycache__/face_alignment.cpython-36.pyc b/__pycache__/face_alignment.cpython-36.pyc\\\\nindex 7dc2c56..6d86f44 100644\\\\nBinary files a/__pycache__/face_alignment.cpython-36.pyc and b/__pycache__/face_alignment.cpython-36.pyc differ\\\\ndiff --git a/align_dataset_userprofs.py b/align_dataset_userprofs.py\\\\nindex d2a3eea..be5e4c2 100644\\\\n--- a/align_dataset_userprofs.py\\\\n+++ b/align_dataset_userprofs.py\\\\n@@ -98,6 +98,8 @@ def main(args):\\\\n                         if nrof_faces>0:\\\\n                             det = bounding_boxes[:,0:4]\\\\n                             img_size = np.asarray(img.shape)[0:2]\\\\n+                            #potentially find the face that matches everything else in the class, and use that face for alignment\\\\n+                            #assuming that there are multiple pictures in that dataset\\\\n                             if nrof_faces>1:\\\\n                                 bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\\\\n                                 img_center = img_size / 2\\\\ndiff --git a/datasets/.DS_Store b/datasets/.DS_Store\\\\nindex 0c90fbd..02cb922 100644\\\\nBinary files a/datasets/.DS_Store and b/datasets/.DS_Store differ\\\\ndiff --git a/datasets/face_data_aligned/bounding_boxes_20314.txt b/datasets/face_data_aligned/bounding_boxes_20314.txt\\\\ndeleted file mode 100644\\\\nindex fcb1749..0000000\\\\n--- a/datasets/face_data_aligned/bounding_boxes_20314.txt\\\\n+++ /dev/null\\\\n@@ -1,7 +0,0 @@\\\\n-datasets/face_data_aligned/Nick_Crompton/Nick_1.png 64 43 237 249\\\\n-datasets/face_data_aligned/Nihal_George/Nihal_1.png 33 20 130 129\\\\n-datasets/face_data_aligned/Evan_Breisch/Evan.png 931 378 1340 885\\\\n-datasets/face_data_aligned/Jake_Paul/Jake_1.png 272 129 591 554\\\\n-datasets/face_data_aligned/Vishal_Joshi/Vishal.png 339 363 706 842\\\\n-datasets/face_data_aligned/Clare_Monahan/Clare.png 1239 634 1431 870\\\\n-datasets/face_data_aligned/Ananth_Chillarige/Ananth_1.png 56 23 150 133\\\\ndiff --git a/datasets/face_data_aligned/revision_info.txt b/datasets/face_data_aligned/revision_info.txt\\\\nindex 26c1dc5..5794123 100644\\\\n--- a/datasets/face_data_aligned/revision_info.txt\\\\n+++ b/datasets/face_data_aligned/revision_info.txt\\\\n@@ -1,5 +1,5 @@\\\\n arguments: demo.py\\\\n --------------------\\\\n-git hash: b\\\\\\\'4faf590600f122c3cd2ab3ab3c85bd3bd2d00822\\\\\\\'\\\\n+git hash: b\\\\\\\'6d8478d2dc0d287bccdd2863a8444b56641599b4\\\\\\\'\\\\n --------------------\\\\n-b\\\\\\\'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\\\\\\\\nindex d2a3eea..044c156 100644\\\\\\\\n--- a/src/align/align_dataset_mtcnn.py\\\\\\\\n+++ b/src/align/align_dataset_mtcnn.py\\\\\\\\n@@ -25,8 +25,10 @@ from __future__ import absolute_import\\\\\\\\n from __future__ import division\\\\\\\\n from __future__ import print_function\\\\\\\\n \\\\\\\\n-from scipy import misc\\\\\\\\n import sys\\\\\\\\n+sys.path.append("..")\\\\\\\\n+\\\\\\\\n+from scipy import misc\\\\\\\\n import os\\\\\\\\n import argparse\\\\\\\\n import tensorflow as tf\\\\\\\\n@@ -99,26 +101,35 @@ def main(args):\\\\\\\\n                             det = bounding_boxes[:,0:4]\\\\\\\\n                             img_size = np.asarray(img.shape)[0:2]\\\\\\\\n                             if nrof_faces>1:\\\\\\\\n-                                bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\\\\\\\\n-                                img_center = img_size / 2\\\\\\\\n-                                offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\\\\\\\\n-                                offset_dist_squared = np.sum(np.power(offsets,2.0),0)\\\\\\\\n-                                index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\\\\\\\\n-                                det = det[index,:]\\\\\\\\n-                            det = np.squeeze(det)\\\\\\\\n-                            bb = np.zeros(4, dtype=np.int32)\\\\\\\\n-                            bb[0] = np.maximum(det[0]-args.margin/2, 0)\\\\\\\\n-                            bb[1] = np.maximum(det[1]-args.margin/2, 0)\\\\\\\\n-                            bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\\\\\\\n-                            bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\\\\\\\n-                            cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\\\\\n-                            scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\\\\\\\\\\\\\'bilinear\\\\\\\\\\\\\\\')\\\\\\\\n-                            nrof_successfully_aligned += 1\\\\\\\\n-                            misc.imsave(output_filename, scaled)\\\\\\\\n-                            text_file.write(\\\\\\\\\\\\\\\'%s %d %d %d %d\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\' % (output_filename, bb[0], bb[1], bb[2], bb[3]))\\\\\\\\n+                                count = 0\\\\\\\\n+                                for sdet in det:\\\\\\\\n+                                    bb = np.zeros(4, dtype=np.int32)\\\\\\\\n+                                    bb[0] = np.maximum(sdet[0]-args.margin/2, 0)\\\\\\\\n+                                    bb[1] = np.maximum(sdet[1]-args.margin/2, 0)\\\\\\\\n+                                    bb[2] = np.minimum(sdet[2]+args.margin/2, img_size[1])\\\\\\\\n+                                    bb[3] = np.minimum(sdet[3]+args.margin/2, img_size[0])\\\\\\\\n+                                    cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\\\\\n+                                    scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\\\\\\\\\\\\\'bilinear\\\\\\\\\\\\\\\')\\\\\\\\n+                                    nrof_successfully_aligned += 1\\\\\\\\n+                                    misc.imsave(output_filename[:-4]+"_"+str(count)+output_filename[-4:], scaled)\\\\\\\\n+                                    text_file.write(\\\\\\\\\\\\\\\'%s %d %d %d %d\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\' % (output_filename[:-4]+"_"+str(count)+output_filename[-4:], bb[0], bb[1], bb[2], bb[3]))\\\\\\\\n+                                    count+=1\\\\\\\\n+                            else:\\\\\\\\n+                                det = np.squeeze(det)\\\\\\\\n+                                bb = np.zeros(4, dtype=np.int32)\\\\\\\\n+                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\\\\\\\\n+                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\\\\\\\\n+                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\\\\\\\n+                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\\\\\\\n+                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\\\\\n+                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\\\\\\\\\\\\\'bilinear\\\\\\\\\\\\\\\')\\\\\\\\n+                                nrof_successfully_aligned += 1\\\\\\\\n+                                misc.imsave(output_filename, scaled)\\\\\\\\n+                                text_file.write(\\\\\\\\\\\\\\\'%s %d %d %d %d\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\' % (output_filename, bb[0], bb[1], bb[2], bb[3]))\\\\\\\\n                         else:\\\\\\\\n                             print(\\\\\\\\\\\\\\\'Unable to align "%s"\\\\\\\\\\\\\\\' % image_path)\\\\\\\\n                             text_file.write(\\\\\\\\\\\\\\\'%s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\' % (output_filename))\\\\\\\\n+                        \\\\\\\\n                             \\\\\\\\n     print(\\\\\\\\\\\\\\\'Total number of images: %d\\\\\\\\\\\\\\\' % nrof_images_total)\\\\\\\\n     print(\\\\\\\\\\\\\\\'Number of successfully aligned images: %d\\\\\\\\\\\\\\\' % nrof_successfully_aligned)\\\\\\\\n@@ -137,6 +148,7 @@ def parse_arguments(argv):\\\\\\\\n         help=\\\\\\\\\\\\\\\'Shuffles the order of images to enable alignment using multiple processes.\\\\\\\\\\\\\\\', action=\\\\\\\\\\\\\\\'store_true\\\\\\\\\\\\\\\')\\\\\\\\n     parser.add_argument(\\\\\\\\\\\\\\\'--gpu_memory_fraction\\\\\\\\\\\\\\\', type=float,\\\\\\\\n         help=\\\\\\\\\\\\\\\'Upper bound on the amount of GPU memory that will be used by the process.\\\\\\\\\\\\\\\', default=1.0)\\\\\\\\n+    print(parser.parse_args(argv))\\\\\\\\n     return parser.parse_args(argv)\\\\\\\\n \\\\\\\\n if __name__ == \\\\\\\\\\\\\\\'__main__\\\\\\\\\\\\\\\':\\\\\\\\ndiff --git a/src/classifier.py b/src/classifier.py\\\\\\\\nindex 749db4d..d76cfff 100644\\\\\\\\n--- a/src/classifier.py\\\\\\\\n+++ b/src/classifier.py\\\\\\\\n@@ -26,15 +26,18 @@ from __future__ import absolute_import\\\\\\\\n from __future__ import division\\\\\\\\n from __future__ import print_function\\\\\\\\n \\\\\\\\n+import sys\\\\\\\\n+sys.path.append("..")\\\\\\\\n+\\\\\\\\n import tensorflow as tf\\\\\\\\n import numpy as np\\\\\\\\n import argparse\\\\\\\\n import facenet\\\\\\\\n import os\\\\\\\\n-import sys\\\\\\\\n+import shutil\\\\\\\\n import math\\\\\\\\n import pickle\\\\\\\\n-from sklearn.svm import SVC\\\\\\\\n+from sklearn import neighbors\\\\\\\\n \\\\\\\\n def main(args):\\\\\\\\n   \\\\\\\\n@@ -53,6 +56,10 @@ def main(args):\\\\\\\\n                     dataset = test_set\\\\\\\\n             else:\\\\\\\\n                 dataset = facenet.get_dataset(args.data_dir)\\\\\\\\n+            \\\\\\\\n+            if (args.mode == \\\\\\\\\\\\\\\'CLASSIFY\\\\\\\\\\\\\\\'):\\\\\\\\n+                training_set = facenet.get_dataset(args.train_dir)\\\\\\\\n+                unaligned_set = facenet.get_dataset(args.unaligned_dir)\\\\\\\\n \\\\\\\\n             # Check that there are at least one training image per class\\\\\\\\n             for cls in dataset:\\\\\\\\n@@ -92,7 +99,7 @@ def main(args):\\\\\\\\n             if (args.mode==\\\\\\\\\\\\\\\'TRAIN\\\\\\\\\\\\\\\'):\\\\\\\\n                 # Train classifier\\\\\\\\n                 print(\\\\\\\\\\\\\\\'Training classifier\\\\\\\\\\\\\\\')\\\\\\\\n-                model = SVC(kernel=\\\\\\\\\\\\\\\'linear\\\\\\\\\\\\\\\', probability=True)\\\\\\\\n+                model = neighbors.KNeighborsClassifier(n_neighbors=1)\\\\\\\\n                 model.fit(emb_array, labels)\\\\\\\\n             \\\\\\\\n                 # Create a list of class names\\\\\\\\n@@ -108,19 +115,35 @@ def main(args):\\\\\\\\n                 print(\\\\\\\\\\\\\\\'Testing classifier\\\\\\\\\\\\\\\')\\\\\\\\n                 with open(classifier_filename_exp, \\\\\\\\\\\\\\\'rb\\\\\\\\\\\\\\\') as infile:\\\\\\\\n                     (model, class_names) = pickle.load(infile)\\\\\\\\n+                \\\\\\\\n+                print(class_names)\\\\\\\\n \\\\\\\\n                 print(\\\\\\\\\\\\\\\'Loaded classifier model from file "%s"\\\\\\\\\\\\\\\' % classifier_filename_exp)\\\\\\\\n \\\\\\\\n                 predictions = model.predict_proba(emb_array)\\\\\\\\n                 best_class_indices = np.argmax(predictions, axis=1)\\\\\\\\n                 best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\\\\\\\\n-                \\\\\\\\n+                                                \\\\\\\\n                 for i in range(len(best_class_indices)):\\\\\\\\n                     print(\\\\\\\\\\\\\\\'%4d  %s: %.3f\\\\\\\\\\\\\\\' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))\\\\\\\\n-                    \\\\\\\\n+\\\\\\\\n+                #File movement to appropriate class in dataset\\\\\\\\n+                for cls in unaligned_set:\\\\\\\\n+                    pths = cls.image_paths\\\\\\\\n+                    count = 0\\\\\\\\n+                    for pth in pths:\\\\\\\\n+                        new_class_name = str(class_names[best_class_indices[count]]).replace(" ","_")\\\\\\\\n+                        destination = "datasets/face_data_unaligned/" + new_class_name +"/"+pth[pth.rfind("/")+1:]\\\\\\\\n+                        os.rename(pth,destination)  \\\\\\\\n+                        count+=1    \\\\\\\\n+                \\\\\\\\n+                #removing aligned unsorted dataset so that they won\\\\\\\\\\\\\\\'t be reclassified\\\\\\\\n+                shutil.rmtree(args.data_dir)\\\\\\\\n+                                 \\\\\\\\n                 accuracy = np.mean(np.equal(best_class_indices, labels))\\\\\\\\n                 print(\\\\\\\\\\\\\\\'Accuracy: %.3f\\\\\\\\\\\\\\\' % accuracy)\\\\\\\\n-                \\\\\\\\n+\\\\\\\\n+\\\\\\\\n             \\\\\\\\n def split_dataset(dataset, min_nrof_images_per_class, nrof_train_images_per_class):\\\\\\\\n     train_set = []\\\\\\\\n@@ -148,6 +171,10 @@ def parse_arguments(argv):\\\\\\\\n     parser.add_argument(\\\\\\\\\\\\\\\'classifier_filename\\\\\\\\\\\\\\\', \\\\\\\\n         help=\\\\\\\\\\\\\\\'Classifier model file name as a pickle (.pkl) file. \\\\\\\\\\\\\\\' + \\\\\\\\n         \\\\\\\\\\\\\\\'For training this is the output and for classification this is an input.\\\\\\\\\\\\\\\')\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\'--train_dir\\\\\\\\\\\\\\\', type=str,\\\\\\\\n+        help=\\\\\\\\\\\\\\\'Path to the data directory containing aligned LFW face patches.\\\\\\\\\\\\\\\')\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\'--unaligned_dir\\\\\\\\\\\\\\\', type=str,\\\\\\\\n+        help=\\\\\\\\\\\\\\\'Path to the data directory containing aligned LFW face patches.\\\\\\\\\\\\\\\', default=\\\\\\\\\\\\\\\'datasets/unsorted_unaligned\\\\\\\\\\\\\\\')\\\\\\\\n     parser.add_argument(\\\\\\\\\\\\\\\'--use_split_dataset\\\\\\\\\\\\\\\', \\\\\\\\n         help=\\\\\\\\\\\\\\\'Indicates that the dataset specified by data_dir should be split into a training and test set. \\\\\\\\\\\\\\\' +  \\\\\\\\n         \\\\\\\\\\\\\\\'Otherwise a separate test set can be specified using the test_data_dir option.\\\\\\\\\\\\\\\', action=\\\\\\\\\\\\\\\'store_true\\\\\\\\\\\\\\\')\\\\\\\\ndiff --git a/src/facenet.py b/src/facenet.py\\\\\\\\nindex 4f139ee..952555b 100644\\\\\\\\n--- a/src/facenet.py\\\\\\\\n+++ b/src/facenet.py\\\\\\\\n@@ -340,7 +340,7 @@ def get_dataset(paths, has_class_directories=True):\\\\\\\\n def get_image_paths(facedir):\\\\\\\\n     image_paths = []\\\\\\\\n     if os.path.isdir(facedir):\\\\\\\\n-        images = os.listdir(facedir)\\\\\\\\n+        images = [a for a in os.listdir(facedir) if not a.startswith(\\\\\\\\\\\\\\\'.\\\\\\\\\\\\\\\')]\\\\\\\\n         image_paths = [os.path.join(facedir,img) for img in images]\\\\\\\\n     return image_paths\\\\\\\'\\\\n\\\\\\\\ No newline at end of file\\\\n+b\\\\\\\'diff --git a/.DS_Store b/.DS_Store\\\\\\\\nindex 2085760..17e5a37 100644\\\\\\\\nBinary files a/.DS_Store and b/.DS_Store differ\\\\\\\\ndiff --git a/.bash_profile b/.bash_profile\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 5509b20..0000000\\\\\\\\n--- a/.bash_profile\\\\\\\\n+++ /dev/null\\\\\\\\n@@ -1 +0,0 @@\\\\\\\\n-export PYTHONPATH=/Users/ananth/Desktop/Machine\\\\\\\\\\\\\\\\ Learning/Face_Classification/facenet/src\\\\\\\\ndiff --git a/__pycache__/face_alignment.cpython-36.pyc b/__pycache__/face_alignment.cpython-36.pyc\\\\\\\\nindex 7dc2c56..6d86f44 100644\\\\\\\\nBinary files a/__pycache__/face_alignment.cpython-36.pyc and b/__pycache__/face_alignment.cpython-36.pyc differ\\\\\\\\ndiff --git a/align_dataset_userprofs.py b/align_dataset_userprofs.py\\\\\\\\nindex d2a3eea..be5e4c2 100644\\\\\\\\n--- a/align_dataset_userprofs.py\\\\\\\\n+++ b/align_dataset_userprofs.py\\\\\\\\n@@ -98,6 +98,8 @@ def main(args):\\\\\\\\n                         if nrof_faces>0:\\\\\\\\n                             det = bounding_boxes[:,0:4]\\\\\\\\n                             img_size = np.asarray(img.shape)[0:2]\\\\\\\\n+                            #potentially find the face that matches everything else in the class, and use that face for alignment\\\\\\\\n+                            #assuming that there are multiple pictures in that dataset\\\\\\\\n                             if nrof_faces>1:\\\\\\\\n                                 bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\\\\\\\\n                                 img_center = img_size / 2\\\\\\\\ndiff --git a/datasets/.DS_Store b/datasets/.DS_Store\\\\\\\\nindex 0c90fbd..c466f5d 100644\\\\\\\\nBinary files a/datasets/.DS_Store and b/datasets/.DS_Store differ\\\\\\\\ndiff --git a/datasets/face_data_aligned/Ananth_Chillarige/Ananth_1.png b/datasets/face_data_aligned/Ananth_Chillarige/Ananth_1.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 583a577..0000000\\\\\\\\nBinary files a/datasets/face_data_aligned/Ananth_Chillarige/Ananth_1.png and /dev/null differ\\\\\\\\ndiff --git a/datasets/face_data_aligned/Clare_Monahan/Clare.png b/datasets/face_data_aligned/Clare_Monahan/Clare.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 1e2591a..0000000\\\\\\\\nBinary files a/datasets/face_data_aligned/Clare_Monahan/Clare.png and /dev/null differ\\\\\\\\ndiff --git a/datasets/face_data_aligned/Evan_Breisch/Evan.png b/datasets/face_data_aligned/Evan_Breisch/Evan.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 77c0ca7..0000000\\\\\\\\nBinary files a/datasets/face_data_aligned/Evan_Breisch/Evan.png and /dev/null differ\\\\\\\\ndiff --git a/datasets/face_data_aligned/Jake_Paul/Jake_1.png b/datasets/face_data_aligned/Jake_Paul/Jake_1.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex c6493b0..0000000\\\\\\\\nBinary files a/datasets/face_data_aligned/Jake_Paul/Jake_1.png and /dev/null differ\\\\\\\\ndiff --git a/datasets/face_data_aligned/Nick_Crompton/Nick_1.png b/datasets/face_data_aligned/Nick_Crompton/Nick_1.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 9478624..0000000\\\\\\\\nBinary files a/datasets/face_data_aligned/Nick_Crompton/Nick_1.png and /dev/null differ\\\\\\\\ndiff --git a/datasets/face_data_aligned/Nihal_George/Nihal_1.png b/datasets/face_data_aligned/Nihal_George/Nihal_1.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 63fa978..0000000\\\\\\\\nBinary files a/datasets/face_data_aligned/Nihal_George/Nihal_1.png and /dev/null differ\\\\\\\\ndiff --git a/datasets/face_data_aligned/Vishal_Joshi/Vishal.png b/datasets/face_data_aligned/Vishal_Joshi/Vishal.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex d727e24..0000000\\\\\\\\nBinary files a/datasets/face_data_aligned/Vishal_Joshi/Vishal.png and /dev/null differ\\\\\\\\ndiff --git a/datasets/face_data_aligned/bounding_boxes_20314.txt b/datasets/face_data_aligned/bounding_boxes_20314.txt\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex fcb1749..0000000\\\\\\\\n--- a/datasets/face_data_aligned/bounding_boxes_20314.txt\\\\\\\\n+++ /dev/null\\\\\\\\n@@ -1,7 +0,0 @@\\\\\\\\n-datasets/face_data_aligned/Nick_Crompton/Nick_1.png 64 43 237 249\\\\\\\\n-datasets/face_data_aligned/Nihal_George/Nihal_1.png 33 20 130 129\\\\\\\\n-datasets/face_data_aligned/Evan_Breisch/Evan.png 931 378 1340 885\\\\\\\\n-datasets/face_data_aligned/Jake_Paul/Jake_1.png 272 129 591 554\\\\\\\\n-datasets/face_data_aligned/Vishal_Joshi/Vishal.png 339 363 706 842\\\\\\\\n-datasets/face_data_aligned/Clare_Monahan/Clare.png 1239 634 1431 870\\\\\\\\n-datasets/face_data_aligned/Ananth_Chillarige/Ananth_1.png 56 23 150 133\\\\\\\\ndiff --git a/datasets/face_data_aligned/revision_info.txt b/datasets/face_data_aligned/revision_info.txt\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 26c1dc5..0000000\\\\\\\\n--- a/datasets/face_data_aligned/revision_info.txt\\\\\\\\n+++ /dev/null\\\\\\\\n@@ -1,5 +0,0 @@\\\\\\\\n-arguments: demo.py\\\\\\\\n---------------------\\\\\\\\n-git hash: b\\\\\\\\\\\\\\\'4faf590600f122c3cd2ab3ab3c85bd3bd2d00822\\\\\\\\\\\\\\\'\\\\\\\\n---------------------\\\\\\\\n-b\\\\\\\\\\\\\\\'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\nindex d2a3eea..044c156 100644\\\\\\\\\\\\\\\\n--- a/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\n+++ b/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\n@@ -25,8 +25,10 @@ from __future__ import absolute_import\\\\\\\\\\\\\\\\n from __future__ import division\\\\\\\\\\\\\\\\n from __future__ import print_function\\\\\\\\\\\\\\\\n \\\\\\\\\\\\\\\\n-from scipy import misc\\\\\\\\\\\\\\\\n import sys\\\\\\\\\\\\\\\\n+sys.path.append("..")\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+from scipy import misc\\\\\\\\\\\\\\\\n import os\\\\\\\\\\\\\\\\n import argparse\\\\\\\\\\\\\\\\n import tensorflow as tf\\\\\\\\\\\\\\\\n@@ -99,26 +101,35 @@ def main(args):\\\\\\\\\\\\\\\\n                             det = bounding_boxes[:,0:4]\\\\\\\\\\\\\\\\n                             img_size = np.asarray(img.shape)[0:2]\\\\\\\\\\\\\\\\n                             if nrof_faces>1:\\\\\\\\\\\\\\\\n-                                bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\\\\\\\\\\\\\\\\n-                                img_center = img_size / 2\\\\\\\\\\\\\\\\n-                                offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\\\\\\\\\\\\\\\\n-                                offset_dist_squared = np.sum(np.power(offsets,2.0),0)\\\\\\\\\\\\\\\\n-                                index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\\\\\\\\\\\\\\\\n-                                det = det[index,:]\\\\\\\\\\\\\\\\n-                            det = np.squeeze(det)\\\\\\\\\\\\\\\\n-                            bb = np.zeros(4, dtype=np.int32)\\\\\\\\\\\\\\\\n-                            bb[0] = np.maximum(det[0]-args.margin/2, 0)\\\\\\\\\\\\\\\\n-                            bb[1] = np.maximum(det[1]-args.margin/2, 0)\\\\\\\\\\\\\\\\n-                            bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\\\\\\\\\\\\\\\n-                            bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\\\\\\\\\\\\\\\n-                            cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\\\\\\\\\\\\\n-                            scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'bilinear\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n-                            nrof_successfully_aligned += 1\\\\\\\\\\\\\\\\n-                            misc.imsave(output_filename, scaled)\\\\\\\\\\\\\\\\n-                            text_file.write(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'%s %d %d %d %d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % (output_filename, bb[0], bb[1], bb[2], bb[3]))\\\\\\\\\\\\\\\\n+                                count = 0\\\\\\\\\\\\\\\\n+                                for sdet in det:\\\\\\\\\\\\\\\\n+                                    bb = np.zeros(4, dtype=np.int32)\\\\\\\\\\\\\\\\n+                                    bb[0] = np.maximum(sdet[0]-args.margin/2, 0)\\\\\\\\\\\\\\\\n+                                    bb[1] = np.maximum(sdet[1]-args.margin/2, 0)\\\\\\\\\\\\\\\\n+                                    bb[2] = np.minimum(sdet[2]+args.margin/2, img_size[1])\\\\\\\\\\\\\\\\n+                                    bb[3] = np.minimum(sdet[3]+args.margin/2, img_size[0])\\\\\\\\\\\\\\\\n+                                    cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\\\\\\\\\\\\\n+                                    scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'bilinear\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n+                                    nrof_successfully_aligned += 1\\\\\\\\\\\\\\\\n+                                    misc.imsave(output_filename[:-4]+"_"+str(count)+output_filename[-4:], scaled)\\\\\\\\\\\\\\\\n+                                    text_file.write(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'%s %d %d %d %d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % (output_filename[:-4]+"_"+str(count)+output_filename[-4:], bb[0], bb[1], bb[2], bb[3]))\\\\\\\\\\\\\\\\n+                                    count+=1\\\\\\\\\\\\\\\\n+                            else:\\\\\\\\\\\\\\\\n+                                det = np.squeeze(det)\\\\\\\\\\\\\\\\n+                                bb = np.zeros(4, dtype=np.int32)\\\\\\\\\\\\\\\\n+                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\\\\\\\\\\\\\\\\n+                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\\\\\\\\\\\\\\\\n+                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\\\\\\\\\\\\\\\n+                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\\\\\\\\\\\\\\\n+                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\\\\\\\\\\\\\n+                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'bilinear\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n+                                nrof_successfully_aligned += 1\\\\\\\\\\\\\\\\n+                                misc.imsave(output_filename, scaled)\\\\\\\\\\\\\\\\n+                                text_file.write(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'%s %d %d %d %d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % (output_filename, bb[0], bb[1], bb[2], bb[3]))\\\\\\\\\\\\\\\\n                         else:\\\\\\\\\\\\\\\\n                             print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Unable to align "%s"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % image_path)\\\\\\\\\\\\\\\\n                             text_file.write(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'%s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % (output_filename))\\\\\\\\\\\\\\\\n+                        \\\\\\\\\\\\\\\\n                             \\\\\\\\\\\\\\\\n     print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Total number of images: %d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % nrof_images_total)\\\\\\\\\\\\\\\\n     print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Number of successfully aligned images: %d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % nrof_successfully_aligned)\\\\\\\\\\\\\\\\n@@ -137,6 +148,7 @@ def parse_arguments(argv):\\\\\\\\\\\\\\\\n         help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Shuffles the order of images to enable alignment using multiple processes.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', action=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'store_true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n     parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'--gpu_memory_fraction\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', type=float,\\\\\\\\\\\\\\\\n         help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Upper bound on the amount of GPU memory that will be used by the process.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', default=1.0)\\\\\\\\\\\\\\\\n+    print(parser.parse_args(argv))\\\\\\\\\\\\\\\\n     return parser.parse_args(argv)\\\\\\\\\\\\\\\\n \\\\\\\\\\\\\\\\n if __name__ == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'__main__\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\':\\\\\\\\\\\\\\\\ndiff --git a/src/classifier.py b/src/classifier.py\\\\\\\\\\\\\\\\nindex 749db4d..d76cfff 100644\\\\\\\\\\\\\\\\n--- a/src/classifier.py\\\\\\\\\\\\\\\\n+++ b/src/classifier.py\\\\\\\\\\\\\\\\n@@ -26,15 +26,18 @@ from __future__ import absolute_import\\\\\\\\\\\\\\\\n from __future__ import division\\\\\\\\\\\\\\\\n from __future__ import print_function\\\\\\\\\\\\\\\\n \\\\\\\\\\\\\\\\n+import sys\\\\\\\\\\\\\\\\n+sys.path.append("..")\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n import tensorflow as tf\\\\\\\\\\\\\\\\n import numpy as np\\\\\\\\\\\\\\\\n import argparse\\\\\\\\\\\\\\\\n import facenet\\\\\\\\\\\\\\\\n import os\\\\\\\\\\\\\\\\n-import sys\\\\\\\\\\\\\\\\n+import shutil\\\\\\\\\\\\\\\\n import math\\\\\\\\\\\\\\\\n import pickle\\\\\\\\\\\\\\\\n-from sklearn.svm import SVC\\\\\\\\\\\\\\\\n+from sklearn import neighbors\\\\\\\\\\\\\\\\n \\\\\\\\\\\\\\\\n def main(args):\\\\\\\\\\\\\\\\n   \\\\\\\\\\\\\\\\n@@ -53,6 +56,10 @@ def main(args):\\\\\\\\\\\\\\\\n                     dataset = test_set\\\\\\\\\\\\\\\\n             else:\\\\\\\\\\\\\\\\n                 dataset = facenet.get_dataset(args.data_dir)\\\\\\\\\\\\\\\\n+            \\\\\\\\\\\\\\\\n+            if (args.mode == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'CLASSIFY\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'):\\\\\\\\\\\\\\\\n+                training_set = facenet.get_dataset(args.train_dir)\\\\\\\\\\\\\\\\n+                unaligned_set = facenet.get_dataset(args.unaligned_dir)\\\\\\\\\\\\\\\\n \\\\\\\\\\\\\\\\n             # Check that there are at least one training image per class\\\\\\\\\\\\\\\\n             for cls in dataset:\\\\\\\\\\\\\\\\n@@ -92,7 +99,7 @@ def main(args):\\\\\\\\\\\\\\\\n             if (args.mode==\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'TRAIN\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'):\\\\\\\\\\\\\\\\n                 # Train classifier\\\\\\\\\\\\\\\\n                 print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Training classifier\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n-                model = SVC(kernel=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'linear\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', probability=True)\\\\\\\\\\\\\\\\n+                model = neighbors.KNeighborsClassifier(n_neighbors=1)\\\\\\\\\\\\\\\\n                 model.fit(emb_array, labels)\\\\\\\\\\\\\\\\n             \\\\\\\\\\\\\\\\n                 # Create a list of class names\\\\\\\\\\\\\\\\n@@ -108,19 +115,35 @@ def main(args):\\\\\\\\\\\\\\\\n                 print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Testing classifier\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n                 with open(classifier_filename_exp, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'rb\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\') as infile:\\\\\\\\\\\\\\\\n                     (model, class_names) = pickle.load(infile)\\\\\\\\\\\\\\\\n+                \\\\\\\\\\\\\\\\n+                print(class_names)\\\\\\\\\\\\\\\\n \\\\\\\\\\\\\\\\n                 print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Loaded classifier model from file "%s"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % classifier_filename_exp)\\\\\\\\\\\\\\\\n \\\\\\\\\\\\\\\\n                 predictions = model.predict_proba(emb_array)\\\\\\\\\\\\\\\\n                 best_class_indices = np.argmax(predictions, axis=1)\\\\\\\\\\\\\\\\n                 best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\\\\\\\\\\\\\\\\n-                \\\\\\\\\\\\\\\\n+                                                \\\\\\\\\\\\\\\\n                 for i in range(len(best_class_indices)):\\\\\\\\\\\\\\\\n                     print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'%4d  %s: %.3f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))\\\\\\\\\\\\\\\\n-                    \\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+                #File movement to appropriate class in dataset\\\\\\\\\\\\\\\\n+                for cls in unaligned_set:\\\\\\\\\\\\\\\\n+                    pths = cls.image_paths\\\\\\\\\\\\\\\\n+                    count = 0\\\\\\\\\\\\\\\\n+                    for pth in pths:\\\\\\\\\\\\\\\\n+                        new_class_name = str(class_names[best_class_indices[count]]).replace(" ","_")\\\\\\\\\\\\\\\\n+                        destination = "datasets/face_data_unaligned/" + new_class_name +"/"+pth[pth.rfind("/")+1:]\\\\\\\\\\\\\\\\n+                        os.rename(pth,destination)  \\\\\\\\\\\\\\\\n+                        count+=1    \\\\\\\\\\\\\\\\n+                \\\\\\\\\\\\\\\\n+                #removing aligned unsorted dataset so that they won\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'t be reclassified\\\\\\\\\\\\\\\\n+                shutil.rmtree(args.data_dir)\\\\\\\\\\\\\\\\n+                                 \\\\\\\\\\\\\\\\n                 accuracy = np.mean(np.equal(best_class_indices, labels))\\\\\\\\\\\\\\\\n                 print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Accuracy: %.3f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % accuracy)\\\\\\\\\\\\\\\\n-                \\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n             \\\\\\\\\\\\\\\\n def split_dataset(dataset, min_nrof_images_per_class, nrof_train_images_per_class):\\\\\\\\\\\\\\\\n     train_set = []\\\\\\\\\\\\\\\\n@@ -148,6 +171,10 @@ def parse_arguments(argv):\\\\\\\\\\\\\\\\n     parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'classifier_filename\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', \\\\\\\\\\\\\\\\n         help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Classifier model file name as a pickle (.pkl) file. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' + \\\\\\\\\\\\\\\\n         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'For training this is the output and for classification this is an input.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'--train_dir\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', type=str,\\\\\\\\\\\\\\\\n+        help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Path to the data directory containing aligned LFW face patches.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'--unaligned_dir\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', type=str,\\\\\\\\\\\\\\\\n+        help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Path to the data directory containing aligned LFW face patches.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', default=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'datasets/unsorted_unaligned\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n     parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'--use_split_dataset\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', \\\\\\\\\\\\\\\\n         help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Indicates that the dataset specified by data_dir should be split into a training and test set. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' +  \\\\\\\\\\\\\\\\n         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Otherwise a separate test set can be specified using the test_data_dir option.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', action=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'store_true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\ndiff --git a/src/facenet.py b/src/facenet.py\\\\\\\\\\\\\\\\nindex 4f139ee..952555b 100644\\\\\\\\\\\\\\\\n--- a/src/facenet.py\\\\\\\\\\\\\\\\n+++ b/src/facenet.py\\\\\\\\\\\\\\\\n@@ -340,7 +340,7 @@ def get_dataset(paths, has_class_directories=True):\\\\\\\\\\\\\\\\n def get_image_paths(facedir):\\\\\\\\\\\\\\\\n     image_paths = []\\\\\\\\\\\\\\\\n     if os.path.isdir(facedir):\\\\\\\\\\\\\\\\n-        images = os.listdir(facedir)\\\\\\\\\\\\\\\\n+        images = [a for a in os.listdir(facedir) if not a.startswith(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')]\\\\\\\\\\\\\\\\n         image_paths = [os.path.join(facedir,img) for img in images]\\\\\\\\\\\\\\\\n     return image_paths\\\\\\\\\\\\\\\'\\\\\\\\n\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\\ndiff --git a/datasets/face_data_unaligned/.DS_Store b/datasets/face_data_unaligned/.DS_Store\\\\\\\\nindex d6c8dd1..ebed479 100644\\\\\\\\nBinary files a/datasets/face_data_unaligned/.DS_Store and b/datasets/face_data_unaligned/.DS_Store differ\\\\\\\\ndiff --git a/datasets/face_data_unaligned/Ananth_Chillarige/.DS_Store b/datasets/face_data_unaligned/Ananth_Chillarige/.DS_Store\\\\\\\\nindex d9ecbd7..507452a 100644\\\\\\\\nBinary files a/datasets/face_data_unaligned/Ananth_Chillarige/.DS_Store and b/datasets/face_data_unaligned/Ananth_Chillarige/.DS_Store differ\\\\\\\\ndiff --git a/datasets/face_data_unaligned/Ananth_Chillarige/3.png b/datasets/face_data_unaligned/Ananth_Chillarige/3.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 3fb7076..0000000\\\\\\\\nBinary files a/datasets/face_data_unaligned/Ananth_Chillarige/3.png and /dev/null differ\\\\\\\\ndiff --git a/datasets/face_data_unaligned/Clare_Monahan/.DS_Store b/datasets/face_data_unaligned/Clare_Monahan/.DS_Store\\\\\\\\nindex a67c8b8..8ed6ed4 100644\\\\\\\\nBinary files a/datasets/face_data_unaligned/Clare_Monahan/.DS_Store and b/datasets/face_data_unaligned/Clare_Monahan/.DS_Store differ\\\\\\\\ndiff --git a/datasets/face_data_unaligned/Clare_Monahan/4.png b/datasets/face_data_unaligned/Clare_Monahan/4.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 3e4daee..0000000\\\\\\\\nBinary files a/datasets/face_data_unaligned/Clare_Monahan/4.png and /dev/null differ\\\\\\\\ndiff --git a/datasets/face_data_unaligned/Evan_Breisch/.DS_Store b/datasets/face_data_unaligned/Evan_Breisch/.DS_Store\\\\\\\\nindex b45ca91..bb746d0 100644\\\\\\\\nBinary files a/datasets/face_data_unaligned/Evan_Breisch/.DS_Store and b/datasets/face_data_unaligned/Evan_Breisch/.DS_Store differ\\\\\\\\ndiff --git a/datasets/face_data_unaligned/Evan_Breisch/6.png b/datasets/face_data_unaligned/Evan_Breisch/6.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 2904eb4..0000000\\\\\\\\nBinary files a/datasets/face_data_unaligned/Evan_Breisch/6.png and /dev/null differ\\\\\\\\ndiff --git a/datasets/face_data_unaligned/Jake_Paul/.DS_Store b/datasets/face_data_unaligned/Jake_Paul/.DS_Store\\\\\\\\nindex f92458e..a2a2e9a 100644\\\\\\\\nBinary files a/datasets/face_data_unaligned/Jake_Paul/.DS_Store and b/datasets/face_data_unaligned/Jake_Paul/.DS_Store differ\\\\\\\\ndiff --git a/datasets/face_data_unaligned/Jake_Paul/0.png b/datasets/face_data_unaligned/Jake_Paul/0.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 754f02f..0000000\\\\\\\\nBinary files a/datasets/face_data_unaligned/Jake_Paul/0.png and /dev/null differ\\\\\\\\ndiff --git a/datasets/face_data_unaligned/Nick_Crompton/.DS_Store b/datasets/face_data_unaligned/Nick_Crompton/.DS_Store\\\\\\\\nindex 00df966..53dfe0f 100644\\\\\\\\nBinary files a/datasets/face_data_unaligned/Nick_Crompton/.DS_Store and b/datasets/face_data_unaligned/Nick_Crompton/.DS_Store differ\\\\\\\\ndiff --git a/datasets/face_data_unaligned/Nick_Crompton/2.png b/datasets/face_data_unaligned/Nick_Crompton/2.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 1e2f47a..0000000\\\\\\\\nBinary files a/datasets/face_data_unaligned/Nick_Crompton/2.png and /dev/null differ\\\\\\\\ndiff --git a/datasets/face_data_unaligned/Nihal_George/.DS_Store b/datasets/face_data_unaligned/Nihal_George/.DS_Store\\\\\\\\nindex 54d50e8..3b0468c 100644\\\\\\\\nBinary files a/datasets/face_data_unaligned/Nihal_George/.DS_Store and b/datasets/face_data_unaligned/Nihal_George/.DS_Store differ\\\\\\\\ndiff --git a/datasets/face_data_unaligned/Nihal_George/1.png b/datasets/face_data_unaligned/Nihal_George/1.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex d6a9e08..0000000\\\\\\\\nBinary files a/datasets/face_data_unaligned/Nihal_George/1.png and /dev/null differ\\\\\\\\ndiff --git a/datasets/face_data_unaligned/Vishal_Joshi/.DS_Store b/datasets/face_data_unaligned/Vishal_Joshi/.DS_Store\\\\\\\\nindex e219548..bd0b138 100644\\\\\\\\nBinary files a/datasets/face_data_unaligned/Vishal_Joshi/.DS_Store and b/datasets/face_data_unaligned/Vishal_Joshi/.DS_Store differ\\\\\\\\ndiff --git a/datasets/face_data_unaligned/Vishal_Joshi/5.png b/datasets/face_data_unaligned/Vishal_Joshi/5.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 646420f..0000000\\\\\\\\nBinary files a/datasets/face_data_unaligned/Vishal_Joshi/5.png and /dev/null differ\\\\\\\\ndiff --git a/datasets/unsorted_unaligned/lol/.DS_Store b/datasets/unsorted_unaligned/lol/.DS_Store\\\\\\\\nindex b0835f0..e3fc768 100644\\\\\\\\nBinary files a/datasets/unsorted_unaligned/lol/.DS_Store and b/datasets/unsorted_unaligned/lol/.DS_Store differ\\\\\\\\ndiff --git a/face_classifier.pkl b/face_classifier.pkl\\\\\\\\nindex a176bac..3369278 100644\\\\\\\\nBinary files a/face_classifier.pkl and b/face_classifier.pkl differ\\\\\\\\ndiff --git a/facenets b/facenets\\\\\\\\nindex 4faf590..e5e8691 160000\\\\\\\\n--- a/facenets\\\\\\\\n+++ b/facenets\\\\\\\\n@@ -1 +1 @@\\\\\\\\n-Subproject commit 4faf590600f122c3cd2ab3ab3c85bd3bd2d00822\\\\\\\\n+Subproject commit e5e86910a6705d42df3a4a8f281d8829e0c0cc3e-dirty\\\\\\\'\\\\n\\\\\\\\ No newline at end of file\\\\ndiff --git a/datasets/face_data_unaligned/.DS_Store b/datasets/face_data_unaligned/.DS_Store\\\\nindex d6c8dd1..096f080 100644\\\\nBinary files a/datasets/face_data_unaligned/.DS_Store and b/datasets/face_data_unaligned/.DS_Store differ\\\\ndiff --git a/datasets/face_data_unaligned/Ananth_Chillarige/.DS_Store b/datasets/face_data_unaligned/Ananth_Chillarige/.DS_Store\\\\nindex d9ecbd7..507452a 100644\\\\nBinary files a/datasets/face_data_unaligned/Ananth_Chillarige/.DS_Store and b/datasets/face_data_unaligned/Ananth_Chillarige/.DS_Store differ\\\\ndiff --git a/datasets/face_data_unaligned/Ananth_Chillarige/3.png b/datasets/face_data_unaligned/Ananth_Chillarige/3.png\\\\ndeleted file mode 100644\\\\nindex 3fb7076..0000000\\\\nBinary files a/datasets/face_data_unaligned/Ananth_Chillarige/3.png and /dev/null differ\\\\ndiff --git a/datasets/face_data_unaligned/Clare_Monahan/.DS_Store b/datasets/face_data_unaligned/Clare_Monahan/.DS_Store\\\\nindex a67c8b8..8ed6ed4 100644\\\\nBinary files a/datasets/face_data_unaligned/Clare_Monahan/.DS_Store and b/datasets/face_data_unaligned/Clare_Monahan/.DS_Store differ\\\\ndiff --git a/datasets/face_data_unaligned/Clare_Monahan/4.png b/datasets/face_data_unaligned/Clare_Monahan/4.png\\\\ndeleted file mode 100644\\\\nindex 3e4daee..0000000\\\\nBinary files a/datasets/face_data_unaligned/Clare_Monahan/4.png and /dev/null differ\\\\ndiff --git a/datasets/face_data_unaligned/Evan_Breisch/.DS_Store b/datasets/face_data_unaligned/Evan_Breisch/.DS_Store\\\\nindex b45ca91..bb746d0 100644\\\\nBinary files a/datasets/face_data_unaligned/Evan_Breisch/.DS_Store and b/datasets/face_data_unaligned/Evan_Breisch/.DS_Store differ\\\\ndiff --git a/datasets/face_data_unaligned/Evan_Breisch/6.png b/datasets/face_data_unaligned/Evan_Breisch/6.png\\\\ndeleted file mode 100644\\\\nindex 2904eb4..0000000\\\\nBinary files a/datasets/face_data_unaligned/Evan_Breisch/6.png and /dev/null differ\\\\ndiff --git a/datasets/face_data_unaligned/Jake_Paul/.DS_Store b/datasets/face_data_unaligned/Jake_Paul/.DS_Store\\\\nindex f92458e..a2a2e9a 100644\\\\nBinary files a/datasets/face_data_unaligned/Jake_Paul/.DS_Store and b/datasets/face_data_unaligned/Jake_Paul/.DS_Store differ\\\\ndiff --git a/datasets/face_data_unaligned/Jake_Paul/0.png b/datasets/face_data_unaligned/Jake_Paul/0.png\\\\ndeleted file mode 100644\\\\nindex 754f02f..0000000\\\\nBinary files a/datasets/face_data_unaligned/Jake_Paul/0.png and /dev/null differ\\\\ndiff --git a/datasets/face_data_unaligned/Nick_Crompton/.DS_Store b/datasets/face_data_unaligned/Nick_Crompton/.DS_Store\\\\nindex 00df966..53dfe0f 100644\\\\nBinary files a/datasets/face_data_unaligned/Nick_Crompton/.DS_Store and b/datasets/face_data_unaligned/Nick_Crompton/.DS_Store differ\\\\ndiff --git a/datasets/face_data_unaligned/Nick_Crompton/2.png b/datasets/face_data_unaligned/Nick_Crompton/2.png\\\\ndeleted file mode 100644\\\\nindex 1e2f47a..0000000\\\\nBinary files a/datasets/face_data_unaligned/Nick_Crompton/2.png and /dev/null differ\\\\ndiff --git a/datasets/face_data_unaligned/Nihal_George/.DS_Store b/datasets/face_data_unaligned/Nihal_George/.DS_Store\\\\nindex 54d50e8..3b0468c 100644\\\\nBinary files a/datasets/face_data_unaligned/Nihal_George/.DS_Store and b/datasets/face_data_unaligned/Nihal_George/.DS_Store differ\\\\ndiff --git a/datasets/face_data_unaligned/Nihal_George/1.png b/datasets/face_data_unaligned/Nihal_George/1.png\\\\ndeleted file mode 100644\\\\nindex d6a9e08..0000000\\\\nBinary files a/datasets/face_data_unaligned/Nihal_George/1.png and /dev/null differ\\\\ndiff --git a/datasets/face_data_unaligned/Vishal_Joshi/.DS_Store b/datasets/face_data_unaligned/Vishal_Joshi/.DS_Store\\\\nindex e219548..bd0b138 100644\\\\nBinary files a/datasets/face_data_unaligned/Vishal_Joshi/.DS_Store and b/datasets/face_data_unaligned/Vishal_Joshi/.DS_Store differ\\\\ndiff --git a/datasets/face_data_unaligned/Vishal_Joshi/5.png b/datasets/face_data_unaligned/Vishal_Joshi/5.png\\\\ndeleted file mode 100644\\\\nindex 646420f..0000000\\\\nBinary files a/datasets/face_data_unaligned/Vishal_Joshi/5.png and /dev/null differ\\\\ndiff --git a/datasets/unsorted_unaligned/lol/.DS_Store b/datasets/unsorted_unaligned/lol/.DS_Store\\\\nindex b0835f0..9f16c38 100644\\\\nBinary files a/datasets/unsorted_unaligned/lol/.DS_Store and b/datasets/unsorted_unaligned/lol/.DS_Store differ\\\\ndiff --git a/face_classifier.pkl b/face_classifier.pkl\\\\nindex a176bac..1ad8ba5 100644\\\\nBinary files a/face_classifier.pkl and b/face_classifier.pkl differ\\\\ndiff --git a/facenets b/facenets\\\\nindex 4faf590..e5e8691 160000\\\\n--- a/facenets\\\\n+++ b/facenets\\\\n@@ -1 +1 @@\\\\n-Subproject commit 4faf590600f122c3cd2ab3ab3c85bd3bd2d00822\\\\n+Subproject commit e5e86910a6705d42df3a4a8f281d8829e0c0cc3e-dirty\\\'\\n\\\\ No newline at end of file\\ndiff --git a/datasets/face_data_unaligned/.DS_Store b/datasets/face_data_unaligned/.DS_Store\\nindex d6c8dd1..096f080 100644\\nBinary files a/datasets/face_data_unaligned/.DS_Store and b/datasets/face_data_unaligned/.DS_Store differ\\ndiff --git a/datasets/face_data_unaligned/Ananth_Chillarige/.DS_Store b/datasets/face_data_unaligned/Ananth_Chillarige/.DS_Store\\nindex d9ecbd7..507452a 100644\\nBinary files a/datasets/face_data_unaligned/Ananth_Chillarige/.DS_Store and b/datasets/face_data_unaligned/Ananth_Chillarige/.DS_Store differ\\ndiff --git a/datasets/face_data_unaligned/Ananth_Chillarige/3.png b/datasets/face_data_unaligned/Ananth_Chillarige/3.png\\ndeleted file mode 100644\\nindex 3fb7076..0000000\\nBinary files a/datasets/face_data_unaligned/Ananth_Chillarige/3.png and /dev/null differ\\ndiff --git a/datasets/face_data_unaligned/Clare_Monahan/.DS_Store b/datasets/face_data_unaligned/Clare_Monahan/.DS_Store\\nindex a67c8b8..8ed6ed4 100644\\nBinary files a/datasets/face_data_unaligned/Clare_Monahan/.DS_Store and b/datasets/face_data_unaligned/Clare_Monahan/.DS_Store differ\\ndiff --git a/datasets/face_data_unaligned/Clare_Monahan/4.png b/datasets/face_data_unaligned/Clare_Monahan/4.png\\ndeleted file mode 100644\\nindex 3e4daee..0000000\\nBinary files a/datasets/face_data_unaligned/Clare_Monahan/4.png and /dev/null differ\\ndiff --git a/datasets/face_data_unaligned/Evan_Breisch/.DS_Store b/datasets/face_data_unaligned/Evan_Breisch/.DS_Store\\nindex b45ca91..bb746d0 100644\\nBinary files a/datasets/face_data_unaligned/Evan_Breisch/.DS_Store and b/datasets/face_data_unaligned/Evan_Breisch/.DS_Store differ\\ndiff --git a/datasets/face_data_unaligned/Evan_Breisch/6.png b/datasets/face_data_unaligned/Evan_Breisch/6.png\\ndeleted file mode 100644\\nindex 2904eb4..0000000\\nBinary files a/datasets/face_data_unaligned/Evan_Breisch/6.png and /dev/null differ\\ndiff --git a/datasets/face_data_unaligned/Jake_Paul/.DS_Store b/datasets/face_data_unaligned/Jake_Paul/.DS_Store\\nindex f92458e..a2a2e9a 100644\\nBinary files a/datasets/face_data_unaligned/Jake_Paul/.DS_Store and b/datasets/face_data_unaligned/Jake_Paul/.DS_Store differ\\ndiff --git a/datasets/face_data_unaligned/Jake_Paul/0.png b/datasets/face_data_unaligned/Jake_Paul/0.png\\ndeleted file mode 100644\\nindex 754f02f..0000000\\nBinary files a/datasets/face_data_unaligned/Jake_Paul/0.png and /dev/null differ\\ndiff --git a/datasets/face_data_unaligned/Nick_Crompton/.DS_Store b/datasets/face_data_unaligned/Nick_Crompton/.DS_Store\\nindex 00df966..53dfe0f 100644\\nBinary files a/datasets/face_data_unaligned/Nick_Crompton/.DS_Store and b/datasets/face_data_unaligned/Nick_Crompton/.DS_Store differ\\ndiff --git a/datasets/face_data_unaligned/Nick_Crompton/2.png b/datasets/face_data_unaligned/Nick_Crompton/2.png\\ndeleted file mode 100644\\nindex 1e2f47a..0000000\\nBinary files a/datasets/face_data_unaligned/Nick_Crompton/2.png and /dev/null differ\\ndiff --git a/datasets/face_data_unaligned/Nihal_George/.DS_Store b/datasets/face_data_unaligned/Nihal_George/.DS_Store\\nindex 54d50e8..3b0468c 100644\\nBinary files a/datasets/face_data_unaligned/Nihal_George/.DS_Store and b/datasets/face_data_unaligned/Nihal_George/.DS_Store differ\\ndiff --git a/datasets/face_data_unaligned/Nihal_George/1.png b/datasets/face_data_unaligned/Nihal_George/1.png\\ndeleted file mode 100644\\nindex d6a9e08..0000000\\nBinary files a/datasets/face_data_unaligned/Nihal_George/1.png and /dev/null differ\\ndiff --git a/datasets/face_data_unaligned/Vishal_Joshi/.DS_Store b/datasets/face_data_unaligned/Vishal_Joshi/.DS_Store\\nindex e219548..bd0b138 100644\\nBinary files a/datasets/face_data_unaligned/Vishal_Joshi/.DS_Store and b/datasets/face_data_unaligned/Vishal_Joshi/.DS_Store differ\\ndiff --git a/datasets/face_data_unaligned/Vishal_Joshi/5.png b/datasets/face_data_unaligned/Vishal_Joshi/5.png\\ndeleted file mode 100644\\nindex 646420f..0000000\\nBinary files a/datasets/face_data_unaligned/Vishal_Joshi/5.png and /dev/null differ\\ndiff --git a/datasets/unsorted_unaligned/lol/.DS_Store b/datasets/unsorted_unaligned/lol/.DS_Store\\nindex b0835f0..eb2b5c0 100644\\nBinary files a/datasets/unsorted_unaligned/lol/.DS_Store and b/datasets/unsorted_unaligned/lol/.DS_Store differ\\ndiff --git a/face_classifier.pkl b/face_classifier.pkl\\nindex a176bac..1ad8ba5 100644\\nBinary files a/face_classifier.pkl and b/face_classifier.pkl differ\\ndiff --git a/facenets b/facenets\\nindex 4faf590..e5e8691 160000\\n--- a/facenets\\n+++ b/facenets\\n@@ -1 +1 @@\\n-Subproject commit 4faf590600f122c3cd2ab3ab3c85bd3bd2d00822\\n+Subproject commit e5e86910a6705d42df3a4a8f281d8829e0c0cc3e-dirty\'\n\\ No newline at end of file\ndiff --git a/datasets/face_data_unaligned/.DS_Store b/datasets/face_data_unaligned/.DS_Store\nindex d6c8dd1..b6beb6b 100644\nBinary files a/datasets/face_data_unaligned/.DS_Store and b/datasets/face_data_unaligned/.DS_Store differ\ndiff --git a/datasets/face_data_unaligned/Ananth_Chillarige/.DS_Store b/datasets/face_data_unaligned/Ananth_Chillarige/.DS_Store\nindex d9ecbd7..507452a 100644\nBinary files a/datasets/face_data_unaligned/Ananth_Chillarige/.DS_Store and b/datasets/face_data_unaligned/Ananth_Chillarige/.DS_Store differ\ndiff --git a/datasets/face_data_unaligned/Ananth_Chillarige/3.png b/datasets/face_data_unaligned/Ananth_Chillarige/3.png\ndeleted file mode 100644\nindex 3fb7076..0000000\nBinary files a/datasets/face_data_unaligned/Ananth_Chillarige/3.png and /dev/null differ\ndiff --git a/datasets/face_data_unaligned/Clare_Monahan/.DS_Store b/datasets/face_data_unaligned/Clare_Monahan/.DS_Store\nindex a67c8b8..8ed6ed4 100644\nBinary files a/datasets/face_data_unaligned/Clare_Monahan/.DS_Store and b/datasets/face_data_unaligned/Clare_Monahan/.DS_Store differ\ndiff --git a/datasets/face_data_unaligned/Clare_Monahan/4.png b/datasets/face_data_unaligned/Clare_Monahan/4.png\ndeleted file mode 100644\nindex 3e4daee..0000000\nBinary files a/datasets/face_data_unaligned/Clare_Monahan/4.png and /dev/null differ\ndiff --git a/datasets/face_data_unaligned/Evan_Breisch/.DS_Store b/datasets/face_data_unaligned/Evan_Breisch/.DS_Store\nindex b45ca91..bb746d0 100644\nBinary files a/datasets/face_data_unaligned/Evan_Breisch/.DS_Store and b/datasets/face_data_unaligned/Evan_Breisch/.DS_Store differ\ndiff --git a/datasets/face_data_unaligned/Evan_Breisch/6.png b/datasets/face_data_unaligned/Evan_Breisch/6.png\ndeleted file mode 100644\nindex 2904eb4..0000000\nBinary files a/datasets/face_data_unaligned/Evan_Breisch/6.png and /dev/null differ\ndiff --git a/datasets/face_data_unaligned/Jake_Paul/.DS_Store b/datasets/face_data_unaligned/Jake_Paul/.DS_Store\nindex f92458e..a2a2e9a 100644\nBinary files a/datasets/face_data_unaligned/Jake_Paul/.DS_Store and b/datasets/face_data_unaligned/Jake_Paul/.DS_Store differ\ndiff --git a/datasets/face_data_unaligned/Jake_Paul/0.png b/datasets/face_data_unaligned/Jake_Paul/0.png\ndeleted file mode 100644\nindex 754f02f..0000000\nBinary files a/datasets/face_data_unaligned/Jake_Paul/0.png and /dev/null differ\ndiff --git a/datasets/face_data_unaligned/Nick_Crompton/.DS_Store b/datasets/face_data_unaligned/Nick_Crompton/.DS_Store\nindex 00df966..53dfe0f 100644\nBinary files a/datasets/face_data_unaligned/Nick_Crompton/.DS_Store and b/datasets/face_data_unaligned/Nick_Crompton/.DS_Store differ\ndiff --git a/datasets/face_data_unaligned/Nick_Crompton/2.png b/datasets/face_data_unaligned/Nick_Crompton/2.png\ndeleted file mode 100644\nindex 1e2f47a..0000000\nBinary files a/datasets/face_data_unaligned/Nick_Crompton/2.png and /dev/null differ\ndiff --git a/datasets/face_data_unaligned/Nihal_George/.DS_Store b/datasets/face_data_unaligned/Nihal_George/.DS_Store\nindex 54d50e8..3b0468c 100644\nBinary files a/datasets/face_data_unaligned/Nihal_George/.DS_Store and b/datasets/face_data_unaligned/Nihal_George/.DS_Store differ\ndiff --git a/datasets/face_data_unaligned/Nihal_George/1.png b/datasets/face_data_unaligned/Nihal_George/1.png\ndeleted file mode 100644\nindex d6a9e08..0000000\nBinary files a/datasets/face_data_unaligned/Nihal_George/1.png and /dev/null differ\ndiff --git a/datasets/face_data_unaligned/Vishal_Joshi/.DS_Store b/datasets/face_data_unaligned/Vishal_Joshi/.DS_Store\nindex e219548..bd0b138 100644\nBinary files a/datasets/face_data_unaligned/Vishal_Joshi/.DS_Store and b/datasets/face_data_unaligned/Vishal_Joshi/.DS_Store differ\ndiff --git a/datasets/face_data_unaligned/Vishal_Joshi/5.png b/datasets/face_data_unaligned/Vishal_Joshi/5.png\ndeleted file mode 100644\nindex 646420f..0000000\nBinary files a/datasets/face_data_unaligned/Vishal_Joshi/5.png and /dev/null differ\ndiff --git a/datasets/unsorted_unaligned/lol/.DS_Store b/datasets/unsorted_unaligned/lol/.DS_Store\nindex b0835f0..eb2b5c0 100644\nBinary files a/datasets/unsorted_unaligned/lol/.DS_Store and b/datasets/unsorted_unaligned/lol/.DS_Store differ\ndiff --git a/face_classifier.pkl b/face_classifier.pkl\nindex a176bac..1ad8ba5 100644\nBinary files a/face_classifier.pkl and b/face_classifier.pkl differ\ndiff --git a/facenets b/facenets\nindex 4faf590..e5e8691 160000\n--- a/facenets\n+++ b/facenets\n@@ -1 +1 @@\n-Subproject commit 4faf590600f122c3cd2ab3ab3c85bd3bd2d00822\n+Subproject commit e5e86910a6705d42df3a4a8f281d8829e0c0cc3e-dirty'